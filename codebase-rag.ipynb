{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygithub\n",
      "  Downloading PyGithub-2.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.55.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pynacl>=1.4.0 (from pygithub)\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl.metadata (8.7 kB)\n",
      "Collecting requests>=2.14.0 (from pygithub)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyjwt>=2.4.0 (from pyjwt[crypto]>=2.4.0->pygithub)\n",
      "  Downloading PyJWT-2.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/paulc1/miniforge3/envs/codebase-rag/lib/python3.10/site-packages (from pygithub) (4.12.2)\n",
      "Collecting urllib3>=1.26.0 (from pygithub)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Deprecated (from pygithub)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.7-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.146-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting certifi>=2019.11.17 (from pinecone-client)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (67 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/paulc1/miniforge3/envs/codebase-rag/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/paulc1/miniforge3/envs/codebase-rag/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.21->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.4.0->pygithub)\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
      "Collecting cffi>=1.4.1 (from pynacl>=1.4.0->pygithub)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.14.0->pygithub)\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->pygithub)\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.4.1->pynacl>=1.4.0->pygithub)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading PyGithub-2.5.0-py3-none-any.whl (375 kB)\n",
      "Downloading langchain-0.3.8-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.55.1-py3-none-any.whl (389 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.4/982.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "Downloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-macosx_11_0_arm64.whl (389 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading jiter-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (311 kB)\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.146-py3-none-any.whl (311 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading PyJWT-2.10.0-py3-none-any.whl (23 kB)\n",
      "Downloading PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl (349 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading pillow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl (178 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading orjson-3.10.12-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.20.4-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.17.0-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading yarl-1.18.0-cp310-cp310-macosx_11_0_arm64.whl (91 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: mpmath, wrapt, urllib3, tqdm, threadpoolctl, tenacity, sympy, SQLAlchemy, sniffio, safetensors, regex, PyYAML, python-dotenv, pyjwt, pydantic-core, pycparser, propcache, pinecone-plugin-interface, Pillow, orjson, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, jsonpointer, joblib, jiter, idna, httpx-sse, h11, fsspec, frozenlist, filelock, distro, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, scipy, requests, pydantic, pinecone-plugin-inference, jsonpatch, jinja2, httpcore, Deprecated, cffi, anyio, aiosignal, torch, tiktoken, scikit-learn, requests-toolbelt, pynacl, pydantic-settings, pinecone-client, huggingface-hub, httpx, dataclasses-json, cryptography, aiohttp, tokenizers, openai, langsmith, transformers, pygithub, langchain-core, sentence-transformers, langchain-text-splitters, langchain_pinecone, langchain, langchain-community\n",
      "Successfully installed Deprecated-1.2.15 MarkupSafe-3.0.2 Pillow-11.0.0 PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 cryptography-43.0.3 dataclasses-json-0.6.7 distro-1.9.0 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.10.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.26.2 idna-3.10 jinja2-3.1.4 jiter-0.8.0 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.8 langchain-community-0.3.8 langchain-core-0.3.21 langchain-text-splitters-0.3.2 langchain_pinecone-0.2.0 langsmith-0.1.146 marshmallow-3.23.1 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 numpy-1.26.4 openai-1.55.1 orjson-3.10.12 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 propcache-0.2.0 pycparser-2.22 pydantic-2.10.2 pydantic-core-2.27.1 pydantic-settings-2.6.1 pygithub-2.5.0 pyjwt-2.10.0 pynacl-1.5.0 python-dotenv-1.0.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.3.1 sniffio-1.3.1 sympy-1.13.1 tenacity-9.0.0 threadpoolctl-3.5.0 tiktoken-0.8.0 tokenizers-0.20.4 torch-2.5.1 tqdm-4.67.1 transformers-4.46.3 typing-inspect-0.9.0 urllib3-2.2.3 wrapt-1.17.0 yarl-1.18.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pygithub langchain langchain-community openai tiktoken pinecone-client langchain_pinecone sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from google.colab import userdata\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "import tempfile\n",
    "from github import Github, Repository\n",
    "from git import Repo\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from langchain.schema import Document\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "# from git import Repo\n",
    "\n",
    "# def clone_repository(repo_url):\n",
    "#     \"\"\"Clones a GitHub repository to a temporary directory.\n",
    "\n",
    "#     Args:\n",
    "#         repo_url: The URL of the GitHub repository.\n",
    "\n",
    "#     Returns:\n",
    "#         The path to the cloned repository.\n",
    "#     \"\"\"\n",
    "#     repo_name = repo_url.split(\"/\")[-1]  # Extract repository name from URL\n",
    "#     repo_path = f\"/content/{repo_name}\"\n",
    "#     Repo.clone_from(repo_url, str(repo_path))\n",
    "#     return str(repo_path)\n",
    "\n",
    "def clone_repository(repo_url: str) -> str:\n",
    "    \"\"\"Clone a repository and return its path\"\"\"\n",
    "    # Use tempfile to get a temporary directory that's writable\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    repo_name = repo_url.split(\"/\")[-1]  # Extract repository name from URL\n",
    "    repo_path = os.path.join(temp_dir, repo_name)\n",
    "    \n",
    "    # Clone the repository\n",
    "    Repo.clone_from(repo_url, str(repo_path))\n",
    "    return str(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = clone_repository(\"https://github.com/CoderAgent/SecureAgent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/pg/wwfxmq4x1vx_t00m5pz1z4nr0000gp/T/tmpwh8fbp6o/SecureAgent\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_EXTENSIONS = {'.py', '.js', '.tsx', '.jsx', '.ipynb', '.java',\n",
    "                         '.cpp', '.ts', '.go', '.rs', '.vue', '.swift', '.c', '.h'}\n",
    "\n",
    "IGNORED_DIRS = {'node_modules', 'venv', 'env', 'dist', 'build', '.git',\n",
    "                '__pycache__', '.next', '.vscode', 'vendor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_content(file_path, repo_path):\n",
    "    \"\"\"\n",
    "    Get content of a single file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict[str, str]]: Dictionary with file name and content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Get relative path from repo root\n",
    "        rel_path = os.path.relpath(file_path, repo_path)\n",
    "\n",
    "        return {\n",
    "            \"name\": rel_path,\n",
    "            \"content\": content\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_main_files_content(repo_path: str):\n",
    "    \"\"\"\n",
    "    Get content of supported code files from the local repository.\n",
    "\n",
    "    Args:\n",
    "        repo_path: Path to the local repository\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing file names and contents\n",
    "    \"\"\"\n",
    "    files_content = []\n",
    "\n",
    "    try:\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            # Skip if current directory is in ignored directories\n",
    "            if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\n",
    "                continue\n",
    "\n",
    "            # Process each file in current directory\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if os.path.splitext(file)[1] in SUPPORTED_EXTENSIONS:\n",
    "                    file_content = get_file_content(file_path, repo_path)\n",
    "                    if file_content:\n",
    "                        files_content.append(file_content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading repository: {str(e)}\")\n",
    "\n",
    "    return files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = get_main_files_content(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'src/app.ts',\n",
       "  'content': 'import { Octokit } from \"@octokit/rest\";\\nimport { createNodeMiddleware } from \"@octokit/webhooks\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\nimport * as http from \"http\";\\nimport { App } from \"octokit\";\\nimport { Review } from \"./constants\";\\nimport { env } from \"./env\";\\nimport { processPullRequest } from \"./review-agent\";\\nimport { applyReview } from \"./reviews\";\\n\\n// This creates a new instance of the Octokit App class.\\nconst reviewApp = new App({\\n  appId: env.GITHUB_APP_ID,\\n  privateKey: env.GITHUB_PRIVATE_KEY,\\n  webhooks: {\\n    secret: env.GITHUB_WEBHOOK_SECRET,\\n  },\\n});\\n\\nconst getChangesPerFile = async (payload: WebhookEventMap[\"pull_request\"]) => {\\n  try {\\n    const octokit = await reviewApp.getInstallationOctokit(\\n      payload.installation.id\\n    );\\n    const { data: files } = await octokit.rest.pulls.listFiles({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      pull_number: payload.pull_request.number,\\n    });\\n    console.dir({ files }, { depth: null });\\n    return files;\\n  } catch (exc) {\\n    console.log(\"exc\");\\n    return [];\\n  }\\n};\\n\\n// This adds an event handler that your code will call later. When this event handler is called, it will log the event to the console. Then, it will use GitHub\\'s REST API to add a comment to the pull request that triggered the event.\\nasync function handlePullRequestOpened({\\n  octokit,\\n  payload,\\n}: {\\n  octokit: Octokit;\\n  payload: WebhookEventMap[\"pull_request\"];\\n}) {\\n  console.log(\\n    `Received a pull request event for #${payload.pull_request.number}`\\n  );\\n  // const reposWithInlineEnabled = new Set<number>([601904706, 701925328]);\\n  // const canInlineSuggest = reposWithInlineEnabled.has(payload.repository.id);\\n  try {\\n    console.log(\"pr info\", {\\n      id: payload.repository.id,\\n      fullName: payload.repository.full_name,\\n      url: payload.repository.html_url,\\n    });\\n    const files = await getChangesPerFile(payload);\\n    const review: Review = await processPullRequest(\\n      octokit,\\n      payload,\\n      files,\\n      true\\n    );\\n    await applyReview({ octokit, payload, review });\\n    console.log(\"Review Submitted\");\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n}\\n\\n// This sets up a webhook event listener. When your app receives a webhook event from GitHub with a `X-GitHub-Event` header value of `pull_request` and an `action` payload value of `opened`, it calls the `handlePullRequestOpened` event handler that is defined above.\\n//@ts-ignore\\nreviewApp.webhooks.on(\"pull_request.opened\", handlePullRequestOpened);\\n\\nconst port = process.env.PORT || 3000;\\nconst reviewWebhook = `/api/review`;\\n\\nconst reviewMiddleware = createNodeMiddleware(reviewApp.webhooks, {\\n  path: \"/api/review\",\\n});\\n\\nconst server = http.createServer((req, res) => {\\n  if (req.url === reviewWebhook) {\\n    reviewMiddleware(req, res);\\n  } else {\\n    res.statusCode = 404;\\n    res.end();\\n  }\\n});\\n\\n// This creates a Node.js server that listens for incoming HTTP requests (including webhook payloads from GitHub) on the specified port. When the server receives a request, it executes the `middleware` function that you defined earlier. Once the server is running, it logs messages to the console to indicate that it is listening.\\nserver.listen(port, () => {\\n  console.log(`Server is listening for events.`);\\n  console.log(\"Press Ctrl + C to quit.\");\\n});\\n'},\n",
       " {'name': 'src/prompts.ts',\n",
       "  'content': 'import { encode, encodeChat } from \"gpt-tokenizer\";\\nimport type { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport type { PRFile } from \"./constants\";\\nimport {\\n  rawPatchStrategy,\\n  smarterContextPatchStrategy,\\n} from \"./context/review\";\\nimport { GROQ_MODEL, type GroqChatModel } from \"./llms/groq\";\\n\\nconst ModelsToTokenLimits: Record<GroqChatModel, number> = {\\n  \"mixtral-8x7b-32768\": 32768,\\n  \"gemma-7b-it\": 32768,\\n  \"llama3-70b-8192\": 8192,\\n  \"llama3-8b-8192\": 8192,\\n};\\n\\nexport const REVIEW_DIFF_PROMPT = `You are PR-Reviewer, a language model designed to review git pull requests.\\nYour task is to provide constructive and concise feedback for the PR, and also provide meaningful code suggestions.\\n\\nExample PR Diff input:\\n\\'\\n## src/file1.py\\n\\n@@ -12,5 +12,5 @@ def func1():\\ncode line that already existed in the file...\\ncode line that already existed in the file....\\n-code line that was removed in the PR\\n+new code line added in the PR\\n code line that already existed in the file...\\n code line that already existed in the file...\\n\\n@@ ... @@ def func2():\\n...\\n\\n\\n## src/file2.py\\n...\\n\\'\\n\\nThe review should focus on new code added in the PR (lines starting with \\'+\\'), and not on code that already existed in the file (lines starting with \\'-\\', or without prefix).\\n\\n- ONLY PROVIDE CODE SUGGESTIONS\\n- Focus on important suggestions like fixing code problems, improving performance, improving security, improving readability\\n- Avoid making suggestions that have already been implemented in the PR code. For example, if you want to add logs, or change a variable to const, or anything else, make sure it isn\\'t already in the PR code.\\n- Don\\'t suggest adding docstring, type hints, or comments.\\n- Suggestions should focus on improving the new code added in the PR (lines starting with \\'+\\')\\n- Do not say things like without seeing the full repo, or full code, or rest of the codebase. Comment only on the code you have!\\n\\nMake sure the provided code suggestions are in the same programming language.\\n\\nDon\\'t repeat the prompt in the answer, and avoid outputting the \\'type\\' and \\'description\\' fields.\\n\\nThink through your suggestions and make exceptional improvements.`;\\n\\nexport const XML_PR_REVIEW_PROMPT = `As the PR-Reviewer AI model, you are tasked to analyze git pull requests across any programming language and provide comprehensive and precise code enhancements. Keep your focus on the new code modifications indicated by \\'+\\' lines in the PR. Your feedback should hunt for code issues, opportunities for performance enhancement, security improvements, and ways to increase readability. \\n\\nEnsure your suggestions are novel and haven\\'t been previously incorporated in the \\'+\\' lines of the PR code. Refrain from proposing enhancements that add docstrings, type hints, or comments. Your recommendations should strictly target the \\'+\\' lines without suggesting the need for complete context such as the whole repo or codebase.\\n\\nYour code suggestions should match the programming language in the PR, steer clear of needless repetition or inclusion of \\'type\\' and \\'description\\' fields.\\n\\nFormulate thoughtful suggestions aimed at strengthening performance, security, and readability, and represent them in an XML format utilizing the tags: <review>, <code>, <suggestion>, <comment>, <type>, <describe>, <filename>. While multiple recommendations can be given, they should all reside within one <review> tag.\\n\\nAlso note, all your code suggestions should follow the valid Markdown syntax for GitHub, identifying the language they\\'re written in, and should be enclosed within backticks (\\\\`\\\\`\\\\`). \\n\\nDon\\'t hesitate to add as many constructive suggestions as are relevant to really improve the effectivity of the code.\\n\\nExample output:\\n\\\\`\\\\`\\\\`\\n<review>\\n  <suggestion>\\n    <describe>[Objective of the newly incorporated code]</describe>\\n    <type>[Category of the given suggestion such as performance, security, etc.]</type>\\n    <comment>[Guidance on enhancing the new code]</comment>\\n    <code>\\n    \\\\`\\\\`\\\\`[Programming Language]\\n    [Equivalent code amendment in the same language]\\n    \\\\`\\\\`\\\\`\\n    </code>\\n    <filename>[name of relevant file]</filename>\\n  </suggestion>\\n  <suggestion>\\n  ...\\n  </suggestion>\\n  ...\\n</review>\\n\\\\`\\\\`\\\\`\\n\\nNote: The \\'comment\\' and \\'describe\\' tags should elucidate the advice and why it’s given, while the \\'code\\' tag hosts the recommended code snippet within proper GitHub Markdown syntax. The \\'type\\' defines the suggestion\\'s category such as performance, security, readability, etc.`;\\n\\nexport const PR_SUGGESTION_TEMPLATE = `{COMMENT}\\n{ISSUE_LINK}\\n\\n{CODE}\\n`;\\n\\nconst assignLineNumbers = (diff: string) => {\\n  const lines = diff.split(\"\\\\n\");\\n  let newLine = 0;\\n  const lineNumbers = [];\\n\\n  for (const line of lines) {\\n    if (line.startsWith(\"@@\")) {\\n      // This is a chunk header. Parse the line numbers.\\n      const match = line.match(/@@ -\\\\d+,\\\\d+ \\\\+(\\\\d+),\\\\d+ @@/);\\n      newLine = parseInt(match[1]);\\n      lineNumbers.push(line); // keep chunk headers as is\\n    } else if (!line.startsWith(\"-\")) {\\n      // This is a line from the new file.\\n      lineNumbers.push(`${newLine++}: ${line}`);\\n    }\\n  }\\n\\n  return lineNumbers.join(\"\\\\n\");\\n};\\n\\nexport const buildSuggestionPrompt = (file: PRFile) => {\\n  const rawPatch = String.raw`${file.patch}`;\\n  const patchWithLines = assignLineNumbers(rawPatch);\\n  return `## ${file.filename}\\\\n\\\\n${patchWithLines}`;\\n};\\n\\nexport const buildPatchPrompt = (file: PRFile) => {\\n  if (file.old_contents == null) {\\n    return rawPatchStrategy(file);\\n  } else {\\n    return smarterContextPatchStrategy(file);\\n  }\\n};\\n\\nexport const getReviewPrompt = (diff: string): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: REVIEW_DIFF_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const getXMLReviewPrompt = (\\n  diff: string\\n): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: XML_PR_REVIEW_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const constructPrompt = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const patches = files.map((file) => patchBuilder(file));\\n  const diff = patches.join(\"\\\\n\");\\n  const convo = convoBuilder(diff);\\n  return convo;\\n};\\n\\nexport const getTokenLength = (blob: string) => {\\n  return encode(blob).length;\\n};\\n\\nexport const isConversationWithinLimit = (\\n  convo: any[],\\n  model: GroqChatModel = GROQ_MODEL\\n) => {\\n  // We don\\'t have the encoder for our Groq model, so we\\'re using\\n  // the one for gpt-3.5-turbo as a rough equivalent.\\n  const convoTokens = encodeChat(convo, \"gpt-3.5-turbo\").length;\\n  return convoTokens < ModelsToTokenLimits[model];\\n};\\n'},\n",
       " {'name': 'src/constants.ts',\n",
       "  'content': 'import { Node } from \"@babel/traverse\";\\nimport { JavascriptParser } from \"./context/language/javascript-parser\";\\nimport { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\n\\nexport interface PRFile {\\n  sha: string;\\n  filename: string;\\n  status:\\n    | \"added\"\\n    | \"removed\"\\n    | \"renamed\"\\n    | \"changed\"\\n    | \"modified\"\\n    | \"copied\"\\n    | \"unchanged\";\\n  additions: number;\\n  deletions: number;\\n  changes: number;\\n  blob_url: string;\\n  raw_url: string;\\n  contents_url: string;\\n  patch?: string;\\n  previous_filename?: string;\\n  patchTokenLength?: number;\\n  old_contents?: string;\\n  current_contents?: string;\\n}\\n\\nexport interface BuilderResponse {\\n  comment: string;\\n  structuredComments: any[];\\n}\\n\\nexport interface Builders {\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[];\\n  responseBuilder: (feedbacks: string[]) => Promise<BuilderResponse>;\\n}\\n\\nexport interface PatchInfo {\\n  hunks: {\\n    oldStart: number;\\n    oldLines: number;\\n    newStart: number;\\n    newLines: number;\\n    lines: string[];\\n  }[];\\n}\\n\\nexport interface PRSuggestion {\\n  describe: string;\\n  type: string;\\n  comment: string;\\n  code: string;\\n  filename: string;\\n  toString: () => string;\\n  identity: () => string;\\n}\\n\\nexport interface CodeSuggestion {\\n  file: string;\\n  line_start: number;\\n  line_end: number;\\n  correction: string;\\n  comment: string;\\n}\\n\\nexport interface ChatMessage {\\n  role: string;\\n  content: string;\\n}\\n\\nexport interface Review {\\n  review: BuilderResponse;\\n  suggestions: CodeSuggestion[];\\n}\\n\\nexport interface BranchDetails {\\n  name: string;\\n  sha: string;\\n  url: string;\\n}\\n\\nexport const sleep = async (ms: number) => {\\n  return new Promise((resolve) => setTimeout(resolve, ms));\\n};\\n\\nexport const processGitFilepath = (filepath: string) => {\\n  // Remove the leading \\'/\\' if it exists\\n  return filepath.startsWith(\"/\") ? filepath.slice(1) : filepath;\\n};\\n\\nexport interface EnclosingContext {\\n  enclosingContext: Node | null;\\n}\\n\\nexport interface AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext;\\n  dryRun(file: string): { valid: boolean; error: string };\\n}\\n\\nconst EXTENSIONS_TO_PARSERS: Map<string, AbstractParser> = new Map([\\n  [\"ts\", new JavascriptParser()],\\n  [\"tsx\", new JavascriptParser()],\\n  [\"js\", new JavascriptParser()],\\n  [\"jsx\", new JavascriptParser()],\\n]);\\n\\nexport const getParserForExtension = (filename: string) => {\\n  const fileExtension = filename.split(\".\").pop().toLowerCase();\\n  return EXTENSIONS_TO_PARSERS.get(fileExtension) || null;\\n};\\n\\nexport const assignLineNumbers = (contents: string): string => {\\n  const lines = contents.split(\"\\\\n\");\\n  let lineNumber = 1;\\n  const linesWithNumbers = lines.map((line) => {\\n    const numberedLine = `${lineNumber}: ${line}`;\\n    lineNumber++;\\n    return numberedLine;\\n  });\\n  return linesWithNumbers.join(\"\\\\n\");\\n};\\n'},\n",
       " {'name': 'src/env.ts',\n",
       "  'content': 'import * as dotenv from \"dotenv\";\\nimport { createPrivateKey } from \"crypto\";\\nimport chalk from \"chalk\";\\n\\ndotenv.config();\\n\\nexport const env = {\\n  GITHUB_APP_ID: process.env.GITHUB_APP_ID,\\n  GITHUB_PRIVATE_KEY: process.env.GITHUB_PRIVATE_KEY,\\n  GITHUB_WEBHOOK_SECRET: process.env.GITHUB_WEBHOOK_SECRET,\\n  GROQ_API_KEY: process.env.GROQ_API_KEY,\\n} as const;\\n\\nlet valid = true;\\n\\nfor (const key in env) {\\n  if (!env[key as keyof typeof env]) {\\n    console.log(\\n      chalk.red(\"✖\") +\\n        chalk.gray(\" Missing required env var: \") +\\n        chalk.bold(`process.env.${key}`)\\n    );\\n    valid = false;\\n  }\\n}\\n\\ntry {\\n  createPrivateKey(env.GITHUB_PRIVATE_KEY);\\n} catch (error) {\\n  console.log(\\n    chalk.red(\\n      \"\\\\n✖ Invalid GitHub private key format for \" +\\n        chalk.bold(`process.env.GITHUB_PRIVATE_KEY`) +\\n        \"\\\\n\"\\n    ) +\\n      chalk.gray(\"  • Must start with: \") +\\n      chalk.bold(\"-----BEGIN RSA PRIVATE KEY-----\\\\n\") +\\n      chalk.gray(\"  • Must end with:   \") +\\n      chalk.bold(\"-----END RSA PRIVATE KEY-----\\\\n\")\\n  );\\n  valid = false;\\n}\\n\\nif (!valid) {\\n  console.log(\\n    chalk.yellow(\"\\\\n⚠ \") +\\n      chalk.bold(\"Please check your .env file and try again.\\\\n\")\\n  );\\n  process.exit(1);\\n}\\n'},\n",
       " {'name': 'src/review-agent.ts',\n",
       "  'content': 'import { Octokit } from \"@octokit/rest\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\nimport { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport * as xml2js from \"xml2js\";\\nimport type {\\n  BranchDetails,\\n  BuilderResponse,\\n  Builders,\\n  CodeSuggestion,\\n  PRFile,\\n  PRSuggestion,\\n} from \"./constants\";\\nimport { PRSuggestionImpl } from \"./data/PRSuggestionImpl\";\\nimport { generateChatCompletion } from \"./llms/chat\";\\nimport {\\n  PR_SUGGESTION_TEMPLATE,\\n  buildPatchPrompt,\\n  constructPrompt,\\n  getReviewPrompt,\\n  getTokenLength,\\n  getXMLReviewPrompt,\\n  isConversationWithinLimit,\\n} from \"./prompts\";\\nimport {\\n  INLINE_FIX_FUNCTION,\\n  getInlineFixPrompt,\\n} from \"./prompts/inline-prompt\";\\nimport { getGitFile } from \"./reviews\";\\n\\nexport const reviewDiff = async (messages: ChatCompletionMessageParam[]) => {\\n  const message = await generateChatCompletion({\\n    messages,\\n  });\\n  return message.content;\\n};\\n\\nexport const reviewFiles = async (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const patches = files.map((file) => patchBuilder(file));\\n  const messages = convoBuilder(patches.join(\"\\\\n\"));\\n  const feedback = await reviewDiff(messages);\\n  return feedback;\\n};\\n\\nconst filterFile = (file: PRFile) => {\\n  const extensionsToIgnore = new Set<string>([\\n    \"pdf\",\\n    \"png\",\\n    \"jpg\",\\n    \"jpeg\",\\n    \"gif\",\\n    \"mp4\",\\n    \"mp3\",\\n    \"md\",\\n    \"json\",\\n    \"env\",\\n    \"toml\",\\n    \"svg\",\\n  ]);\\n  const filesToIgnore = new Set<string>([\\n    \"package-lock.json\",\\n    \"yarn.lock\",\\n    \".gitignore\",\\n    \"package.json\",\\n    \"tsconfig.json\",\\n    \"poetry.lock\",\\n    \"readme.md\",\\n  ]);\\n  const filename = file.filename.toLowerCase().split(\"/\").pop();\\n  if (filename && filesToIgnore.has(filename)) {\\n    console.log(`Filtering out ignored file: ${file.filename}`);\\n    return false;\\n  }\\n  const splitFilename = file.filename.toLowerCase().split(\".\");\\n  if (splitFilename.length <= 1) {\\n    console.log(`Filtering out file with no extension: ${file.filename}`);\\n    return false;\\n  }\\n  const extension = splitFilename.pop()?.toLowerCase();\\n  if (extension && extensionsToIgnore.has(extension)) {\\n    console.log(`Filtering out file with ignored extension: ${file.filename} (.${extension})`);\\n    return false;\\n  }\\n  return true;\\n};\\n\\nconst groupFilesByExtension = (files: PRFile[]): Map<string, PRFile[]> => {\\n  const filesByExtension: Map<string, PRFile[]> = new Map();\\n\\n  files.forEach((file) => {\\n    const extension = file.filename.split(\".\").pop()?.toLowerCase();\\n    if (extension) {\\n      if (!filesByExtension.has(extension)) {\\n        filesByExtension.set(extension, []);\\n      }\\n      filesByExtension.get(extension)?.push(file);\\n    }\\n  });\\n\\n  return filesByExtension;\\n};\\n\\n// all of the files here can be processed with the prompt at minimum\\nconst processWithinLimitFiles = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const processGroups: PRFile[][] = [];\\n  const convoWithinModelLimit = isConversationWithinLimit(\\n    constructPrompt(files, patchBuilder, convoBuilder)\\n  );\\n\\n  console.log(`Within model token limits: ${convoWithinModelLimit}`);\\n  if (!convoWithinModelLimit) {\\n    const grouped = groupFilesByExtension(files);\\n    for (const [extension, filesForExt] of grouped.entries()) {\\n      const extGroupWithinModelLimit = isConversationWithinLimit(\\n        constructPrompt(filesForExt, patchBuilder, convoBuilder)\\n      );\\n      if (extGroupWithinModelLimit) {\\n        processGroups.push(filesForExt);\\n      } else {\\n        // extension group exceeds model limit\\n        console.log(\\n          \"Processing files per extension that exceed model limit ...\"\\n        );\\n        let currentGroup: PRFile[] = [];\\n        filesForExt.sort((a, b) => a.patchTokenLength - b.patchTokenLength);\\n        filesForExt.forEach((file) => {\\n          const isPotentialGroupWithinLimit = isConversationWithinLimit(\\n            constructPrompt([...currentGroup, file], patchBuilder, convoBuilder)\\n          );\\n          if (isPotentialGroupWithinLimit) {\\n            currentGroup.push(file);\\n          } else {\\n            processGroups.push(currentGroup);\\n            currentGroup = [file];\\n          }\\n        });\\n        if (currentGroup.length > 0) {\\n          processGroups.push(currentGroup);\\n        }\\n      }\\n    }\\n  } else {\\n    processGroups.push(files);\\n  }\\n  return processGroups;\\n};\\n\\nconst stripRemovedLines = (originalFile: PRFile) => {\\n  // remove lines starting with a \\'-\\'\\n  const originalPatch = String.raw`${originalFile.patch}`;\\n  const strippedPatch = originalPatch\\n    .split(\"\\\\n\")\\n    .filter((line) => !line.startsWith(\"-\"))\\n    .join(\"\\\\n\");\\n  return { ...originalFile, patch: strippedPatch };\\n};\\n\\nconst processOutsideLimitFiles = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const processGroups: PRFile[][] = [];\\n  if (files.length == 0) {\\n    return processGroups;\\n  }\\n  files = files.map((file) => stripRemovedLines(file));\\n  const convoWithinModelLimit = isConversationWithinLimit(\\n    constructPrompt(files, patchBuilder, convoBuilder)\\n  );\\n  if (convoWithinModelLimit) {\\n    processGroups.push(files);\\n  } else {\\n    const exceedingLimits: PRFile[] = [];\\n    const withinLimits: PRFile[] = [];\\n    files.forEach((file) => {\\n      const isFileConvoWithinLimits = isConversationWithinLimit(\\n        constructPrompt([file], patchBuilder, convoBuilder)\\n      );\\n      if (isFileConvoWithinLimits) {\\n        withinLimits.push(file);\\n      } else {\\n        exceedingLimits.push(file);\\n      }\\n    });\\n    const withinLimitsGroup = processWithinLimitFiles(\\n      withinLimits,\\n      patchBuilder,\\n      convoBuilder\\n    );\\n    withinLimitsGroup.forEach((group) => {\\n      processGroups.push(group);\\n    });\\n    if (exceedingLimits.length > 0) {\\n      console.log(\"TODO: Need to further chunk large file changes.\");\\n      // throw \"Unimplemented\"\\n    }\\n  }\\n  return processGroups;\\n};\\n\\nconst processXMLSuggestions = async (feedbacks: string[]) => {\\n  const xmlParser = new xml2js.Parser();\\n  const parsedSuggestions = await Promise.all(\\n    feedbacks.map((fb) => {\\n      fb = fb\\n        .split(\"<code>\")\\n        .join(\"<code><![CDATA[\")\\n        .split(\"</code>\")\\n        .join(\"]]></code>\");\\n      console.log(fb);\\n      return xmlParser.parseStringPromise(fb);\\n    })\\n  );\\n  // gets suggestion arrays [[suggestion], [suggestion]], then flattens\\n  const allSuggestions = parsedSuggestions\\n    .map((sug) => sug.review.suggestion)\\n    .flat(1);\\n  const suggestions: PRSuggestion[] = allSuggestions.map((rawSuggestion) => {\\n    const lines = rawSuggestion.code[0].trim().split(\"\\\\n\");\\n    lines[0] = lines[0].trim();\\n    lines[lines.length - 1] = lines[lines.length - 1].trim();\\n    const code = lines.join(\"\\\\n\");\\n\\n    return new PRSuggestionImpl(\\n      rawSuggestion.describe[0],\\n      rawSuggestion.type[0],\\n      rawSuggestion.comment[0],\\n      code,\\n      rawSuggestion.filename[0]\\n    );\\n  });\\n  return suggestions;\\n};\\n\\nconst generateGithubIssueUrl = (\\n  owner: string,\\n  repoName: string,\\n  title: string,\\n  body: string,\\n  codeblock?: string\\n) => {\\n  const encodedTitle = encodeURIComponent(title);\\n  const encodedBody = encodeURIComponent(body);\\n  const encodedCodeBlock = codeblock\\n    ? encodeURIComponent(`\\\\n${codeblock}\\\\n`)\\n    : \"\";\\n\\n  let url = `https://github.com/${owner}/${repoName}/issues/new?title=${encodedTitle}&body=${encodedBody}${encodedCodeBlock}`;\\n\\n  if (url.length > 2048) {\\n    url = `https://github.com/${owner}/${repoName}/issues/new?title=${encodedTitle}&body=${encodedBody}`;\\n  }\\n  return `[Create Issue](${url})`;\\n};\\n\\nexport const dedupSuggestions = (\\n  suggestions: PRSuggestion[]\\n): PRSuggestion[] => {\\n  const suggestionsMap = new Map<string, PRSuggestion>();\\n  suggestions.forEach((suggestion) => {\\n    suggestionsMap.set(suggestion.identity(), suggestion);\\n  });\\n  return Array.from(suggestionsMap.values());\\n};\\n\\nconst convertPRSuggestionToComment = (\\n  owner: string,\\n  repo: string,\\n  suggestions: PRSuggestion[]\\n): string[] => {\\n  const suggestionsMap = new Map<string, PRSuggestion[]>();\\n  suggestions.forEach((suggestion) => {\\n    if (!suggestionsMap.has(suggestion.filename)) {\\n      suggestionsMap.set(suggestion.filename, []);\\n    }\\n    suggestionsMap.get(suggestion.filename).push(suggestion);\\n  });\\n  const comments: string[] = [];\\n  for (let [filename, suggestions] of suggestionsMap) {\\n    const temp = [`## ${filename}\\\\n`];\\n    suggestions.forEach((suggestion: PRSuggestion) => {\\n      const issueLink = generateGithubIssueUrl(\\n        owner,\\n        repo,\\n        suggestion.describe,\\n        suggestion.comment,\\n        suggestion.code\\n      );\\n      temp.push(\\n        PR_SUGGESTION_TEMPLATE.replace(\"{COMMENT}\", suggestion.comment)\\n          .replace(\"{CODE}\", suggestion.code)\\n          .replace(\"{ISSUE_LINK}\", issueLink)\\n      );\\n    });\\n    comments.push(temp.join(\"\\\\n\"));\\n  }\\n  return comments;\\n};\\n\\nconst xmlResponseBuilder = async (\\n  owner: string,\\n  repoName: string,\\n  feedbacks: string[]\\n): Promise<BuilderResponse> => {\\n  console.log(\"IN XML RESPONSE BUILDER\");\\n  const parsedXMLSuggestions = await processXMLSuggestions(feedbacks);\\n  const comments = convertPRSuggestionToComment(\\n    owner,\\n    repoName,\\n    dedupSuggestions(parsedXMLSuggestions)\\n  );\\n  const commentBlob = comments.join(\"\\\\n\");\\n  return { comment: commentBlob, structuredComments: parsedXMLSuggestions };\\n};\\n\\nconst curriedXmlResponseBuilder = (owner: string, repoName: string) => {\\n  return (feedbacks: string[]) =>\\n    xmlResponseBuilder(owner, repoName, feedbacks);\\n};\\n\\nconst basicResponseBuilder = async (\\n  feedbacks: string[]\\n): Promise<BuilderResponse> => {\\n  console.log(\"IN BASIC RESPONSE BUILDER\");\\n  const commentBlob = feedbacks.join(\"\\\\n\");\\n  return { comment: commentBlob, structuredComments: [] };\\n};\\n\\nexport const reviewChanges = async (\\n  files: PRFile[],\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[],\\n  responseBuilder: (responses: string[]) => Promise<BuilderResponse>\\n) => {\\n  const patchBuilder = buildPatchPrompt;\\n  const filteredFiles = files.filter((file) => filterFile(file));\\n  filteredFiles.map((file) => {\\n    file.patchTokenLength = getTokenLength(patchBuilder(file));\\n  });\\n  // further subdivide if necessary, maybe group files by common extension?\\n  const patchesWithinModelLimit: PRFile[] = [];\\n  // these single file patches are larger than the full model context\\n  const patchesOutsideModelLimit: PRFile[] = [];\\n\\n  filteredFiles.forEach((file) => {\\n    const patchWithPromptWithinLimit = isConversationWithinLimit(\\n      constructPrompt([file], patchBuilder, convoBuilder)\\n    );\\n    if (patchWithPromptWithinLimit) {\\n      patchesWithinModelLimit.push(file);\\n    } else {\\n      patchesOutsideModelLimit.push(file);\\n    }\\n  });\\n\\n  console.log(`files within limits: ${patchesWithinModelLimit.length}`);\\n  const withinLimitsPatchGroups = processWithinLimitFiles(\\n    patchesWithinModelLimit,\\n    patchBuilder,\\n    convoBuilder\\n  );\\n  const exceedingLimitsPatchGroups = processOutsideLimitFiles(\\n    patchesOutsideModelLimit,\\n    patchBuilder,\\n    convoBuilder\\n  );\\n  console.log(`${withinLimitsPatchGroups.length} within limits groups.`);\\n  console.log(\\n    `${patchesOutsideModelLimit.length} files outside limit, skipping them.`\\n  );\\n\\n  const groups = [...withinLimitsPatchGroups, ...exceedingLimitsPatchGroups];\\n\\n  const feedbacks = await Promise.all(\\n    groups.map((patchGroup) => {\\n      return reviewFiles(patchGroup, patchBuilder, convoBuilder);\\n    })\\n  );\\n  try {\\n    return await responseBuilder(feedbacks);\\n  } catch (exc) {\\n    console.log(\"XML parsing error\");\\n    console.log(exc);\\n    throw exc;\\n  }\\n};\\n\\nconst indentCodeFix = (\\n  file: string,\\n  code: string,\\n  lineStart: number\\n): string => {\\n  const fileLines = file.split(\"\\\\n\");\\n  const firstLine = fileLines[lineStart - 1];\\n  const codeLines = code.split(\"\\\\n\");\\n  const indentation = firstLine.match(/^(\\\\s*)/)[0];\\n  const indentedCodeLines = codeLines.map((line) => indentation + line);\\n  return indentedCodeLines.join(\"\\\\n\");\\n};\\n\\nconst isCodeSuggestionNew = (\\n  contents: string,\\n  suggestion: CodeSuggestion\\n): boolean => {\\n  const fileLines = contents.split(\"\\\\n\");\\n  const targetLines = fileLines\\n    .slice(suggestion.line_start - 1, suggestion.line_end)\\n    .join(\"\\\\n\");\\n  if (targetLines.trim() == suggestion.correction.trim()) {\\n    // same as existing code.\\n    return false;\\n  }\\n  return true;\\n};\\n\\nexport const generateInlineComments = async (\\n  suggestion: PRSuggestion,\\n  file: PRFile\\n): Promise<CodeSuggestion> => {\\n  try {\\n    const messages = getInlineFixPrompt(file.current_contents, suggestion);\\n    const { function_call } = await generateChatCompletion({\\n      messages,\\n      functions: [INLINE_FIX_FUNCTION],\\n      function_call: { name: INLINE_FIX_FUNCTION.name },\\n    });\\n    if (!function_call) {\\n      throw new Error(\"No function call found\");\\n    }\\n    const args = JSON.parse(function_call.arguments);\\n    const initialCode = String.raw`${args[\"code\"]}`;\\n    const indentedCode = indentCodeFix(\\n      file.current_contents,\\n      initialCode,\\n      args[\"lineStart\"]\\n    );\\n    const codeFix = {\\n      file: suggestion.filename,\\n      line_start: args[\"lineStart\"],\\n      line_end: args[\"lineEnd\"],\\n      correction: indentedCode,\\n      comment: args[\"comment\"],\\n    };\\n    if (isCodeSuggestionNew(file.current_contents, codeFix)) {\\n      return codeFix;\\n    }\\n    return null;\\n  } catch (exc) {\\n    console.log(exc);\\n    return null;\\n  }\\n};\\n\\nconst preprocessFile = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  file: PRFile\\n) => {\\n  const { base, head } = payload.pull_request;\\n  const baseBranch: BranchDetails = {\\n    name: base.ref,\\n    sha: base.sha,\\n    url: payload.pull_request.url,\\n  };\\n  const currentBranch: BranchDetails = {\\n    name: head.ref,\\n    sha: head.sha,\\n    url: payload.pull_request.url,\\n  };\\n  // Handle scenario where file does not exist!!\\n  const [oldContents, currentContents] = await Promise.all([\\n    getGitFile(octokit, payload, baseBranch, file.filename),\\n    getGitFile(octokit, payload, currentBranch, file.filename),\\n  ]);\\n\\n  if (oldContents.content != null) {\\n    file.old_contents = String.raw`${oldContents.content}`;\\n  } else {\\n    file.old_contents = null;\\n  }\\n\\n  if (currentContents.content != null) {\\n    file.current_contents = String.raw`${currentContents.content}`;\\n  } else {\\n    file.current_contents = null;\\n  }\\n};\\n\\nconst reviewChangesRetry = async (files: PRFile[], builders: Builders[]) => {\\n  for (const { convoBuilder, responseBuilder } of builders) {\\n    try {\\n      console.log(`Trying with convoBuilder: ${convoBuilder.name}.`);\\n      return await reviewChanges(files, convoBuilder, responseBuilder);\\n    } catch (error) {\\n      console.log(\\n        `Error with convoBuilder: ${convoBuilder.name}, trying next one. Error: ${error}`\\n      );\\n    }\\n  }\\n  throw new Error(\"All convoBuilders failed.\");\\n};\\n\\nexport const processPullRequest = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  files: PRFile[],\\n  includeSuggestions = false\\n) => {\\n  console.dir({ files }, { depth: null });\\n  const filteredFiles = files.filter((file) => filterFile(file));\\n  console.dir({ filteredFiles }, { depth: null });\\n  if (filteredFiles.length == 0) {\\n    console.log(\"Nothing to comment on, all files were filtered out. The PR Agent does not support the following file types: pdf, png, jpg, jpeg, gif, mp4, mp3, md, json, env, toml, svg, package-lock.json, yarn.lock, .gitignore, package.json, tsconfig.json, poetry.lock, readme.md\");\\n    return {\\n      review: null,\\n      suggestions: [],\\n    };\\n  }\\n  await Promise.all(\\n    filteredFiles.map((file) => {\\n      return preprocessFile(octokit, payload, file);\\n    })\\n  );\\n  const owner = payload.repository.owner.login;\\n  const repoName = payload.repository.name;\\n  const curriedXMLResponseBuilder = curriedXmlResponseBuilder(owner, repoName);\\n  if (includeSuggestions) {\\n    const reviewComments = await reviewChangesRetry(filteredFiles, [\\n      {\\n        convoBuilder: getXMLReviewPrompt,\\n        responseBuilder: curriedXMLResponseBuilder,\\n      },\\n      {\\n        convoBuilder: getReviewPrompt,\\n        responseBuilder: basicResponseBuilder,\\n      },\\n    ]);\\n    let inlineComments: CodeSuggestion[] = [];\\n    if (reviewComments.structuredComments.length > 0) {\\n      console.log(\"STARTING INLINE COMMENT PROCESSING\");\\n      inlineComments = await Promise.all(\\n        reviewComments.structuredComments.map((suggestion) => {\\n          // find relevant file\\n          const file = files.find(\\n            (file) => file.filename === suggestion.filename\\n          );\\n          if (file == null) {\\n            return null;\\n          }\\n          return generateInlineComments(suggestion, file);\\n        })\\n      );\\n    }\\n    const filteredInlineComments = inlineComments.filter(\\n      (comment) => comment !== null\\n    );\\n    return {\\n      review: reviewComments,\\n      suggestions: filteredInlineComments,\\n    };\\n  } else {\\n    const [review] = await Promise.all([\\n      reviewChangesRetry(filteredFiles, [\\n        {\\n          convoBuilder: getXMLReviewPrompt,\\n          responseBuilder: curriedXMLResponseBuilder,\\n        },\\n        {\\n          convoBuilder: getReviewPrompt,\\n          responseBuilder: basicResponseBuilder,\\n        },\\n      ]),\\n    ]);\\n\\n    return {\\n      review,\\n      suggestions: [],\\n    };\\n  }\\n};\\n'},\n",
       " {'name': 'src/reviews.ts',\n",
       "  'content': 'import {\\n  BranchDetails,\\n  BuilderResponse,\\n  CodeSuggestion,\\n  Review,\\n  processGitFilepath,\\n} from \"./constants\";\\nimport { Octokit } from \"@octokit/rest\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\n\\nconst postGeneralReviewComment = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  review: string\\n) => {\\n  try {\\n    await octokit.request(\\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        issue_number: payload.pull_request.number,\\n        body: review,\\n        headers: {\\n          \"x-github-api-version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n};\\n\\nconst postInlineComment = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  suggestion: CodeSuggestion\\n) => {\\n  try {\\n    const line = suggestion.line_end;\\n    let startLine = null;\\n    if (suggestion.line_end != suggestion.line_start) {\\n      startLine = suggestion.line_start;\\n    }\\n    const suggestionBody = `${suggestion.comment}\\\\n\\\\`\\\\`\\\\`suggestion\\\\n${suggestion.correction}`;\\n\\n    await octokit.request(\\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        pull_number: payload.pull_request.number,\\n        body: suggestionBody,\\n        commit_id: payload.pull_request.head.sha,\\n        path: suggestion.file,\\n        line: line,\\n        ...(startLine ? { start_line: startLine } : {}),\\n        // position: suggestion.line_start,\\n        // subject_type: \"line\",\\n        start_side: \"RIGHT\",\\n        side: \"RIGHT\",\\n        headers: {\\n          \"X-GitHub-Api-Version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n};\\n\\nexport const applyReview = async ({\\n  octokit,\\n  payload,\\n  review,\\n}: {\\n  octokit: Octokit;\\n  payload: WebhookEventMap[\"pull_request\"];\\n  review: Review;\\n}) => {\\n  let commentPromise = null;\\n  const comment = review.review?.comment;\\n  if (comment != null) {\\n    commentPromise = postGeneralReviewComment(octokit, payload, comment);\\n  }\\n  const suggestionPromises = review.suggestions.map((suggestion) =>\\n    postInlineComment(octokit, payload, suggestion)\\n  );\\n  await Promise.all([\\n    ...(commentPromise ? [commentPromise] : []),\\n    ...suggestionPromises,\\n  ]);\\n};\\n\\nconst addLineNumbers = (contents: string) => {\\n  const rawContents = String.raw`${contents}`;\\n  const prepended = rawContents\\n    .split(\"\\\\n\")\\n    .map((line, idx) => `${idx + 1}: ${line}`)\\n    .join(\"\\\\n\");\\n  return prepended;\\n};\\n\\nexport const getGitFile = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"] | WebhookEventMap[\"pull_request\"],\\n  branch: BranchDetails,\\n  filepath: string\\n) => {\\n  try {\\n    const response = await octokit.request(\\n      \"GET /repos/{owner}/{repo}/contents/{path}\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        path: filepath,\\n        ref: branch.name, // specify the branch name here\\n        headers: {\\n          \"X-GitHub-Api-Version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n    //@ts-ignore\\n    const decodedContent = Buffer.from(\\n      response.data.content,\\n      \"base64\"\\n    ).toString(\"utf8\");\\n    //@ts-ignore\\n    return { content: decodedContent, sha: response.data.sha };\\n  } catch (exc) {\\n    if (exc.status === 404) {\\n      return { content: null, sha: null };\\n    }\\n    console.log(exc);\\n    throw exc;\\n  }\\n};\\n\\nexport const getFileContents = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"],\\n  branch: BranchDetails,\\n  filepath: string\\n) => {\\n  const gitFile = await getGitFile(\\n    octokit,\\n    payload,\\n    branch,\\n    processGitFilepath(filepath)\\n  );\\n  const fileWithLines = `# ${filepath}\\\\n${addLineNumbers(gitFile.content)}`;\\n  return { result: fileWithLines, functionString: `Opening file: ${filepath}` };\\n};\\n\\nexport const commentIssue = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"],\\n  comment: string\\n) => {\\n  await octokit.rest.issues.createComment({\\n    owner: payload.repository.owner.login,\\n    repo: payload.repository.name,\\n    issue_number: payload.issue.number,\\n    body: comment,\\n  });\\n};\\n\\nexport const createBranch = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"]\\n) => {\\n  let branchDetails = null;\\n  try {\\n    const title = payload.issue.title.replace(/\\\\s/g, \"-\").substring(0, 15);\\n\\n    const hash = Math.random().toString(36).substring(2, 7);\\n    const subName = `${title}-${hash}`.substring(0, 20);\\n    const branchName = `Code-Bot/${subName}`;\\n    // Get the default branch for the repository\\n    const { data: repo } = await octokit.rest.repos.get({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n    });\\n\\n    // Get the commit SHA of the default branch\\n    const { data: ref } = await octokit.rest.git.getRef({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      ref: `heads/${repo.default_branch}`,\\n    });\\n\\n    // Create a new branch from the commit SHA\\n    const { data: newBranch } = await octokit.rest.git.createRef({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      ref: `refs/heads/${branchName}`,\\n      sha: ref.object.sha,\\n    });\\n\\n    console.log(newBranch);\\n\\n    branchDetails = {\\n      name: branchName,\\n      sha: newBranch.object.sha,\\n      url: newBranch.url,\\n    };\\n    let branchUrl = `https://github.com/${payload.repository.owner.login}/${payload.repository.name}/tree/${branchName}`;\\n    const branchComment = `Branch created: [${branchName}](${branchUrl})`;\\n    await commentIssue(octokit, payload, branchComment);\\n\\n    console.log(`Branch ${branchName} created`);\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n  return branchDetails;\\n};\\n'},\n",
       " {'name': 'src/context/review.ts',\n",
       "  'content': 'import {\\n  AbstractParser,\\n  PRFile,\\n  PatchInfo,\\n  getParserForExtension,\\n} from \"../constants\";\\nimport * as diff from \"diff\";\\nimport { JavascriptParser } from \"./language/javascript-parser\";\\nimport { Node } from \"@babel/traverse\";\\n\\nconst expandHunk = (\\n  contents: string,\\n  hunk: diff.Hunk,\\n  linesAbove: number = 5,\\n  linesBelow: number = 5\\n) => {\\n  const fileLines = contents.split(\"\\\\n\");\\n  const curExpansion: string[] = [];\\n  const start = Math.max(0, hunk.oldStart - 1 - linesAbove);\\n  const end = Math.min(\\n    fileLines.length,\\n    hunk.oldStart - 1 + hunk.oldLines + linesBelow\\n  );\\n\\n  for (let i = start; i < hunk.oldStart - 1; i++) {\\n    curExpansion.push(fileLines[i]);\\n  }\\n\\n  curExpansion.push(\\n    `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`\\n  );\\n  hunk.lines.forEach((line) => {\\n    if (!curExpansion.includes(line)) {\\n      curExpansion.push(line);\\n    }\\n  });\\n\\n  for (let i = hunk.oldStart - 1 + hunk.oldLines; i < end; i++) {\\n    curExpansion.push(fileLines[i]);\\n  }\\n  return curExpansion.join(\"\\\\n\");\\n};\\n\\nconst expandFileLines = (\\n  file: PRFile,\\n  linesAbove: number = 5,\\n  linesBelow: number = 5\\n) => {\\n  const fileLines = file.old_contents.split(\"\\\\n\");\\n  const patches: PatchInfo[] = diff.parsePatch(file.patch);\\n  const expandedLines: string[][] = [];\\n  patches.forEach((patch) => {\\n    patch.hunks.forEach((hunk) => {\\n      const curExpansion: string[] = [];\\n      const start = Math.max(0, hunk.oldStart - 1 - linesAbove);\\n      const end = Math.min(\\n        fileLines.length,\\n        hunk.oldStart - 1 + hunk.oldLines + linesBelow\\n      );\\n\\n      for (let i = start; i < hunk.oldStart - 1; i++) {\\n        curExpansion.push(fileLines[i]);\\n      }\\n\\n      curExpansion.push(\\n        `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`\\n      );\\n      hunk.lines.forEach((line) => {\\n        if (!curExpansion.includes(line)) {\\n          curExpansion.push(line);\\n        }\\n      });\\n\\n      for (let i = hunk.oldStart - 1 + hunk.oldLines; i < end; i++) {\\n        curExpansion.push(fileLines[i]);\\n      }\\n      expandedLines.push(curExpansion);\\n    });\\n  });\\n\\n  return expandedLines;\\n};\\n\\nexport const expandedPatchStrategy = (file: PRFile) => {\\n  const expandedPatches = expandFileLines(file);\\n  const expansions = expandedPatches\\n    .map((patchLines) => patchLines.join(\"\\\\n\"))\\n    .join(\"\\\\n\\\\n\");\\n  return `## ${file.filename}\\\\n\\\\n${expansions}`;\\n};\\n\\nexport const rawPatchStrategy = (file: PRFile) => {\\n  return `## ${file.filename}\\\\n\\\\n${file.patch}`;\\n};\\n\\nconst trimHunk = (hunk: diff.Hunk): diff.Hunk => {\\n  const startIdx = hunk.lines.findIndex(\\n    (line) => line.startsWith(\"+\") || line.startsWith(\"-\")\\n  );\\n  const endIdx = hunk.lines\\n    .slice()\\n    .reverse()\\n    .findIndex((line) => line.startsWith(\"+\") || line.startsWith(\"-\"));\\n  const editLines = hunk.lines.slice(startIdx, hunk.lines.length - endIdx);\\n  return { ...hunk, lines: editLines, newStart: startIdx + hunk.newStart };\\n};\\n\\nconst buildingScopeString = (\\n  currentFile: string,\\n  scope: Node,\\n  hunk: diff.Hunk\\n) => {\\n  const res: string[] = [];\\n  const trimmedHunk = trimHunk(hunk);\\n  const functionStartLine = scope.loc.start.line;\\n  const functionEndLine = scope.loc.end.line;\\n  const updatedFileLines = currentFile.split(\"\\\\n\");\\n  // Extract the lines of the function\\n  const functionContext = updatedFileLines.slice(\\n    functionStartLine - 1,\\n    functionEndLine\\n  );\\n  // Calculate the index where the changes should be injected into the function\\n  const injectionIdx =\\n    hunk.newStart -\\n    functionStartLine +\\n    hunk.lines.findIndex(\\n      (line) => line.startsWith(\"+\") || line.startsWith(\"-\")\\n    );\\n  // Count the number of lines that should be dropped from the function\\n  const dropCount = trimmedHunk.lines.filter(\\n    (line) => !line.startsWith(\"-\")\\n  ).length;\\n\\n  const hunkHeader = `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`;\\n  // Inject the changes into the function, dropping the necessary lines\\n  functionContext.splice(injectionIdx, dropCount, ...trimmedHunk.lines);\\n\\n  res.push(functionContext.join(\"\\\\n\"));\\n  res.unshift(hunkHeader);\\n  return res;\\n};\\n\\n/*\\nline nums are 0 index, file is 1 index\\n*/\\nconst combineHunks = (\\n  file: string,\\n  overlappingHunks: diff.Hunk[]\\n): diff.Hunk => {\\n  if (!overlappingHunks || overlappingHunks.length === 0) {\\n    throw \"Overlapping hunks are empty, this should never happen.\";\\n  }\\n  const sortedHunks = overlappingHunks.sort((a, b) => a.newStart - b.newStart);\\n  const fileLines = file.split(\"\\\\n\");\\n  let lastHunkEnd = sortedHunks[0].newStart + sortedHunks[0].newLines;\\n\\n  const combinedHunk: diff.Hunk = {\\n    oldStart: sortedHunks[0].oldStart,\\n    oldLines: sortedHunks[0].oldLines,\\n    newStart: sortedHunks[0].newStart,\\n    newLines: sortedHunks[0].newLines,\\n    lines: [...sortedHunks[0].lines],\\n    linedelimiters: [...sortedHunks[0].linedelimiters],\\n  };\\n\\n  for (let i = 1; i < sortedHunks.length; i++) {\\n    const hunk = sortedHunks[i];\\n\\n    // If there\\'s a gap between the last hunk and this one, add the lines in between\\n    if (hunk.newStart > lastHunkEnd) {\\n      combinedHunk.lines.push(\\n        ...fileLines.slice(lastHunkEnd - 1, hunk.newStart - 1)\\n      );\\n      combinedHunk.newLines += hunk.newStart - lastHunkEnd;\\n    }\\n\\n    combinedHunk.oldLines += hunk.oldLines;\\n    combinedHunk.newLines += hunk.newLines;\\n    combinedHunk.lines.push(...hunk.lines);\\n    combinedHunk.linedelimiters.push(...hunk.linedelimiters);\\n\\n    lastHunkEnd = hunk.newStart + hunk.newLines;\\n  }\\n  return combinedHunk;\\n};\\n\\nconst diffContextPerHunk = (file: PRFile, parser: AbstractParser) => {\\n  const updatedFile = diff.applyPatch(file.old_contents, file.patch);\\n  const patches = diff.parsePatch(file.patch);\\n  if (!updatedFile || typeof updatedFile !== \"string\") {\\n    console.log(\"APPLYING PATCH ERROR - FALLINGBACK\");\\n    throw \"THIS SHOULD NOT HAPPEN!\";\\n  }\\n\\n  const hunks: diff.Hunk[] = [];\\n  const order: number[] = [];\\n  const scopeRangeHunkMap = new Map<string, diff.Hunk[]>();\\n  const scopeRangeNodeMap = new Map<string, Node>();\\n  const expandStrategy: diff.Hunk[] = [];\\n\\n  patches.forEach((p) => {\\n    p.hunks.forEach((hunk) => {\\n      hunks.push(hunk);\\n    });\\n  });\\n\\n  hunks.forEach((hunk, idx) => {\\n    try {\\n      const trimmedHunk = trimHunk(hunk);\\n      const insertions = hunk.lines.filter((line) =>\\n        line.startsWith(\"+\")\\n      ).length;\\n      const lineStart = trimmedHunk.newStart;\\n      const lineEnd = lineStart + insertions;\\n      const largestEnclosingFunction = parser.findEnclosingContext(\\n        updatedFile,\\n        lineStart,\\n        lineEnd\\n      ).enclosingContext;\\n\\n      if (largestEnclosingFunction) {\\n        const enclosingRangeKey = `${largestEnclosingFunction.loc.start.line} -> ${largestEnclosingFunction.loc.end.line}`;\\n        let existingHunks = scopeRangeHunkMap.get(enclosingRangeKey) || [];\\n        existingHunks.push(hunk);\\n        scopeRangeHunkMap.set(enclosingRangeKey, existingHunks);\\n        scopeRangeNodeMap.set(enclosingRangeKey, largestEnclosingFunction);\\n      } else {\\n        throw \"No enclosing function.\";\\n      }\\n      order.push(idx);\\n    } catch (exc) {\\n      console.log(file.filename);\\n      console.log(\"NORMAL STRATEGY\");\\n      console.log(exc);\\n      expandStrategy.push(hunk);\\n      order.push(idx);\\n    }\\n  });\\n\\n  const scopeStategy: [string, diff.Hunk][] = []; // holds map range key and combined hunk: [[key, hunk]]\\n  for (const [range, hunks] of scopeRangeHunkMap.entries()) {\\n    const combinedHunk = combineHunks(updatedFile, hunks);\\n    scopeStategy.push([range, combinedHunk]);\\n  }\\n\\n  const contexts: string[] = [];\\n  scopeStategy.forEach(([rangeKey, hunk]) => {\\n    const context = buildingScopeString(\\n      updatedFile,\\n      scopeRangeNodeMap.get(rangeKey),\\n      hunk\\n    ).join(\"\\\\n\");\\n    contexts.push(context);\\n  });\\n  expandStrategy.forEach((hunk) => {\\n    const context = expandHunk(file.old_contents, hunk);\\n    contexts.push(context);\\n  });\\n  return contexts;\\n};\\n\\nconst functionContextPatchStrategy = (\\n  file: PRFile,\\n  parser: AbstractParser\\n): string => {\\n  let res = null;\\n  try {\\n    const contextChunks = diffContextPerHunk(file, parser);\\n    res = `## ${file.filename}\\\\n\\\\n${contextChunks.join(\"\\\\n\\\\n\")}`;\\n  } catch (exc) {\\n    console.log(exc);\\n    res = expandedPatchStrategy(file);\\n  }\\n  return res;\\n};\\n\\nexport const smarterContextPatchStrategy = (file: PRFile) => {\\n  const parser: AbstractParser = getParserForExtension(file.filename);\\n  if (parser != null) {\\n    return functionContextPatchStrategy(file, parser);\\n  } else {\\n    return expandedPatchStrategy(file);\\n  }\\n};\\n'},\n",
       " {'name': 'src/context/language/python-parser.ts',\n",
       "  'content': 'import { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n'},\n",
       " {'name': 'src/context/language/javascript-parser.ts',\n",
       "  'content': 'import { AbstractParser, EnclosingContext } from \"../../constants\";\\nimport * as parser from \"@babel/parser\";\\nimport traverse, { NodePath, Node } from \"@babel/traverse\";\\n\\nconst processNode = (\\n  path: NodePath<Node>,\\n  lineStart: number,\\n  lineEnd: number,\\n  largestSize: number,\\n  largestEnclosingContext: Node | null\\n) => {\\n  const { start, end } = path.node.loc;\\n  if (start.line <= lineStart && lineEnd <= end.line) {\\n    const size = end.line - start.line;\\n    if (size > largestSize) {\\n      largestSize = size;\\n      largestEnclosingContext = path.node;\\n    }\\n  }\\n  return { largestSize, largestEnclosingContext };\\n};\\n\\nexport class JavascriptParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    const ast = parser.parse(file, {\\n      sourceType: \"module\",\\n      plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n    });\\n    let largestEnclosingContext: Node = null;\\n    let largestSize = 0;\\n    traverse(ast, {\\n      Function(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n      TSInterfaceDeclaration(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n    });\\n    return {\\n      enclosingContext: largestEnclosingContext,\\n    } as EnclosingContext;\\n  }\\n\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    try {\\n      const ast = parser.parse(file, {\\n        sourceType: \"module\",\\n        plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n      });\\n      return {\\n        valid: true,\\n        error: \"\",\\n      };\\n    } catch (exc) {\\n      return {\\n        valid: false,\\n        error: exc,\\n      };\\n    }\\n  }\\n}\\n'},\n",
       " {'name': 'src/prompts/inline-prompt.ts',\n",
       "  'content': 'import { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport { PRSuggestion } from \"../constants\";\\n\\nexport const INLINE_FIX_PROMPT = `In this task, you are provided with a code suggestion in XML format, along with the corresponding file content. Your task is to radiate from this suggestion and draft a precise code fix. Here\\'s how your input will look:\\n\\n\\\\`\\\\`\\\\`xml\\n  <suggestion>\\n    <describe>Your Description Here</describe>\\n    <type>Your Type Here</type>\\n    <comment>Your Suggestions Here</comment>\\n    <code>Original Code Here</code>\\n    <filename>File Name Here</filename>\\n  </suggestion>\\n\\\\`\\\\`\\\\`\\n\\n{file}\\n\\nThe \\'comment\\' field contains specific code modification instructions. Based on these instructions, you\\'re required to formulate a precise code fix. Bear in mind that the fix must include only the lines between the starting line (linestart) and ending line (lineend) where the changes are applied.\\n\\nThe adjusted code doesn\\'t necessarily need to be standalone valid code, but when incorporated into the corresponding file, it must result in valid, functional code, without errors. Ensure to include only the specific lines affected by the modifications. Avoid including placeholders such as \\'rest of code...\\'\\n\\nPlease interpret the given directions and apply the necessary changes to the provided suggestion and file content. Make the modifications unambiguous and appropriate for utilizing in an inline suggestion on GitHub.`;\\n\\nexport const INLINE_FIX_FUNCTION = {\\n  name: \"fix\",\\n  description: \"The code fix to address the suggestion and rectify the issue\",\\n  parameters: {\\n    type: \"object\",\\n    properties: {\\n      comment: {\\n        type: \"string\",\\n        description: \"Why this change improves the code\",\\n      },\\n      code: {\\n        type: \"string\",\\n        description: \"Modified Code Snippet\",\\n      },\\n      lineStart: {\\n        type: \"number\",\\n        description: \"Starting Line Number\",\\n      },\\n      lineEnd: {\\n        type: \"number\",\\n        description: \"Ending Line Number\",\\n      },\\n    },\\n  },\\n  required: [\"action\"],\\n};\\n\\nconst INLINE_USER_MESSAGE_TEMPLATE = `{SUGGESTION}\\n\\n{FILE}`;\\n\\nconst assignFullLineNumers = (contents: string): string => {\\n  const lines = contents.split(\"\\\\n\");\\n  let lineNumber = 1;\\n  const linesWithNumbers = lines.map((line) => {\\n    const numberedLine = `${lineNumber}: ${line}`;\\n    lineNumber++;\\n    return numberedLine;\\n  });\\n  return linesWithNumbers.join(\"\\\\n\");\\n};\\n\\nexport const getInlineFixPrompt = (\\n  fileContents: string,\\n  suggestion: PRSuggestion\\n): ChatCompletionMessageParam[] => {\\n  const userMessage = INLINE_USER_MESSAGE_TEMPLATE.replace(\\n    \"{SUGGESTION}\",\\n    suggestion.toString()\\n  ).replace(\"{FILE}\", assignFullLineNumers(fileContents));\\n  return [\\n    { role: \"system\", content: INLINE_FIX_PROMPT },\\n    { role: \"user\", content: userMessage },\\n  ];\\n};\\n'},\n",
       " {'name': 'src/llms/chat.ts',\n",
       "  'content': 'import { ChatCompletionCreateParamsNonStreaming } from \"groq-sdk/resources/chat/completions\";\\nimport { groq, GROQ_MODEL } from \"./groq\";\\n\\nexport const generateChatCompletion = async (\\n  options: Omit<ChatCompletionCreateParamsNonStreaming, \"model\">\\n) => {\\n  const response = await groq.chat.completions.create({\\n    model: GROQ_MODEL,\\n    temperature: 0,\\n    ...options,\\n  });\\n  return response.choices[0].message;\\n};\\n'},\n",
       " {'name': 'src/llms/groq.ts',\n",
       "  'content': 'import { Groq } from \"groq-sdk\";\\nimport { env } from \"../env\";\\nimport { ChatCompletionCreateParamsBase } from \"groq-sdk/resources/chat/completions\";\\n\\nexport const groq = new Groq({\\n  apiKey: env.GROQ_API_KEY,\\n});\\n\\nexport type GroqChatModel = ChatCompletionCreateParamsBase[\"model\"];\\n\\nexport const GROQ_MODEL: GroqChatModel = \"mixtral-8x7b-32768\";\\n'},\n",
       " {'name': 'src/data/PRSuggestionImpl.ts',\n",
       "  'content': 'import { PRSuggestion } from \"../constants\";\\n\\nexport class PRSuggestionImpl implements PRSuggestion {\\n  describe: string;\\n  type: string;\\n  comment: string;\\n  code: string;\\n  filename: string;\\n\\n  constructor(\\n    describe: string,\\n    type: string,\\n    comment: string,\\n    code: string,\\n    filename: string\\n  ) {\\n    this.describe = describe;\\n    this.type = type;\\n    this.comment = comment;\\n    this.code = code;\\n    this.filename = filename;\\n  }\\n\\n  toString(): string {\\n    const xmlElements = [\\n      `<suggestion>`,\\n      `  <describe>${this.describe}</describe>`,\\n      `  <type>${this.type}</type>`,\\n      `  <comment>${this.comment}</comment>`,\\n      `  <code>${this.code}</code>`,\\n      `  <filename>${this.filename}</filename>`,\\n      `</suggestion>`,\\n    ];\\n    return xmlElements.join(\"\\\\n\");\\n  }\\n\\n  identity(): string {\\n    return `${this.filename}:${this.comment}`;\\n  }\\n}\\n'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am a programmer\"\n",
    "\n",
    "embeddings = get_huggingface_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.81737561e-02, -3.02658021e-03, -4.77465168e-02,  1.86379459e-02,\n",
       "        3.14538553e-02,  1.87256038e-02, -1.52535010e-02, -6.77293763e-02,\n",
       "       -1.26903830e-02,  1.28427902e-02,  5.80700971e-02,  4.00234573e-02,\n",
       "        3.27073075e-02,  7.12998137e-02,  5.56373149e-02,  1.68628637e-02,\n",
       "        6.97603971e-02, -5.02620190e-02,  6.13149907e-03, -1.46559495e-02,\n",
       "       -4.51954640e-03,  4.82934080e-02, -2.53051538e-02, -1.97862601e-03,\n",
       "       -4.36902978e-02, -2.41507683e-02,  1.29505266e-02, -3.78607749e-03,\n",
       "       -2.05718856e-02,  1.09819151e-01,  3.07671353e-03, -2.80443449e-02,\n",
       "       -1.55807203e-02, -1.24790575e-02,  1.75239234e-06, -2.93753087e-03,\n",
       "       -1.43048689e-02,  4.88385893e-02, -6.21115342e-02,  2.95061544e-02,\n",
       "       -1.40470751e-02,  2.20708121e-02,  1.13068130e-02,  4.70892638e-02,\n",
       "        7.58303842e-03, -8.30338395e-05,  6.67821839e-02, -1.21320179e-02,\n",
       "        4.39393567e-03,  2.47454196e-02,  1.02529237e-02, -6.54435391e-03,\n",
       "       -5.53144375e-03, -1.88788120e-02, -5.65547235e-02, -8.61436129e-03,\n",
       "        9.17805824e-03,  4.72955853e-02,  3.66610549e-02,  4.16185223e-02,\n",
       "       -2.49964371e-02, -6.78152367e-02,  6.27579540e-03,  2.28893161e-02,\n",
       "        5.63387759e-02,  4.84213531e-02,  4.10140045e-02, -7.02803135e-02,\n",
       "        2.37882659e-02,  1.48006203e-03,  1.69444345e-02, -2.93292366e-02,\n",
       "       -1.11225815e-02,  4.25578170e-02,  7.48561788e-03, -4.39105034e-02,\n",
       "       -2.76734885e-02,  4.78422083e-02, -2.08099023e-03, -3.47002149e-02,\n",
       "       -2.33029108e-02, -6.11977139e-03, -2.89494675e-02, -4.91500832e-02,\n",
       "       -2.88692862e-02,  2.06755586e-02, -5.95946796e-03, -7.59895565e-03,\n",
       "       -1.26038622e-02,  1.25793153e-02,  2.28638644e-03,  4.14937327e-04,\n",
       "        4.59123477e-02,  2.63599344e-02, -2.33863704e-02, -1.22355642e-02,\n",
       "        7.56903086e-03,  1.67932697e-02, -1.77069977e-02,  3.53326416e-03,\n",
       "       -4.28935997e-02, -6.92439359e-03, -1.01978984e-02,  1.43273706e-02,\n",
       "       -4.73027537e-03,  1.27360933e-02,  3.79430726e-02,  4.01016474e-02,\n",
       "       -3.45703103e-02,  2.56913770e-02, -2.62000877e-02, -1.15285087e-02,\n",
       "        1.04734311e-02, -2.22316841e-04,  5.68597317e-02,  5.21822684e-02,\n",
       "       -2.19243318e-02,  5.35193719e-02, -1.23544689e-03,  3.53213027e-02,\n",
       "       -1.67341139e-02, -2.27758978e-02,  1.72112137e-02,  6.45435825e-02,\n",
       "        6.58219634e-03, -4.08306271e-02, -3.10202092e-02,  2.23484822e-03,\n",
       "       -2.57478263e-02, -3.19050439e-02,  1.29830176e-02, -2.61128582e-02,\n",
       "       -1.10535268e-02, -3.96891609e-02, -4.76280646e-03,  2.39801407e-02,\n",
       "       -3.50866094e-02,  5.66668883e-02,  8.37152300e-04, -3.63665968e-02,\n",
       "        2.61066537e-02, -1.61578543e-02, -1.83447283e-02, -5.55726364e-02,\n",
       "       -9.33757424e-03,  1.87277179e-02, -1.93999857e-02,  1.79932415e-02,\n",
       "        2.42580287e-02,  1.58868004e-02, -4.28456999e-02,  4.69506271e-02,\n",
       "       -4.28000614e-02,  8.86242429e-04,  4.31625657e-02,  2.16580331e-02,\n",
       "        4.42674235e-02, -5.37621118e-02, -4.43628281e-02,  6.75782189e-02,\n",
       "       -4.26716404e-03, -5.40975109e-02,  7.05882981e-02,  1.95075665e-02,\n",
       "       -5.82847632e-02, -1.76912863e-02,  4.58377600e-02,  3.58919352e-02,\n",
       "       -7.60992197e-03, -5.24801528e-03,  5.15250824e-02, -2.74889264e-02,\n",
       "       -4.65321951e-02,  7.44159743e-02,  1.47800753e-02, -3.88491899e-02,\n",
       "        7.06428736e-02,  4.29205075e-02, -1.74887814e-02, -2.61149984e-02,\n",
       "       -3.05779148e-02, -1.17235586e-01,  8.63820780e-03,  6.41902685e-02,\n",
       "       -4.60082944e-03,  3.55602279e-02, -3.05580050e-02,  1.20734936e-02,\n",
       "       -1.23474607e-02, -2.77650934e-02, -6.63865730e-03, -2.58687548e-02,\n",
       "       -8.91563669e-03,  3.51216644e-02,  1.96691416e-02, -3.83135304e-02,\n",
       "        3.85989435e-02, -2.49588932e-03, -1.08006075e-02, -4.35230620e-02,\n",
       "       -2.68697497e-02, -4.37627397e-02, -4.02603075e-02,  6.88361600e-02,\n",
       "        9.86469630e-03, -9.01128948e-02,  2.05337978e-03, -2.20368411e-02,\n",
       "        4.24189754e-02, -2.84167770e-02,  5.78805618e-02, -5.54718031e-03,\n",
       "       -4.35151793e-02,  2.42435653e-02, -3.82710458e-03, -2.14941800e-02,\n",
       "       -1.22398569e-03,  2.74500810e-02,  2.23104246e-02,  3.29487100e-02,\n",
       "       -2.18574293e-02,  3.27293016e-02,  1.59088131e-02, -1.32143656e-02,\n",
       "       -7.62804830e-03, -5.78399040e-02, -3.64293554e-03,  7.60958949e-03,\n",
       "       -1.68876618e-03, -2.50102580e-03, -1.27403960e-02,  1.64351892e-02,\n",
       "        1.83964018e-02,  3.17538939e-02, -2.61214431e-02, -2.62165852e-02,\n",
       "        4.38267998e-02, -3.44015881e-02,  4.29135561e-03, -3.37396823e-02,\n",
       "       -3.75597477e-02,  1.88001227e-02, -1.56786516e-02,  4.88208495e-02,\n",
       "        6.33974746e-02, -2.97320057e-02,  3.43256816e-02,  3.55255157e-02,\n",
       "        4.25960170e-03, -2.92933080e-02, -2.89668385e-02,  3.46055180e-02,\n",
       "        5.35491796e-04,  8.82586464e-02, -4.19692323e-03,  9.53756459e-03,\n",
       "       -6.43944647e-03,  4.12336364e-03, -7.03926310e-02, -2.01490289e-03,\n",
       "        3.63084786e-02, -7.75657147e-02,  2.24708412e-02,  9.34198219e-03,\n",
       "        2.36142445e-02, -1.47393551e-02,  3.98179777e-02, -9.37734097e-02,\n",
       "       -6.38186708e-02,  1.89054608e-02, -2.23646127e-02,  1.08355572e-02,\n",
       "       -1.92357302e-02, -5.91063523e-04, -3.84382345e-02,  6.88673882e-03,\n",
       "       -7.17332866e-03, -8.10824260e-02, -2.26356965e-02,  3.27473916e-02,\n",
       "       -5.98205160e-03, -1.41920578e-02, -4.02820259e-02, -4.84507717e-02,\n",
       "       -4.44588810e-02, -5.58692543e-03,  5.88093558e-03, -5.55807799e-02,\n",
       "       -3.65542546e-02,  9.06208996e-03,  4.40732297e-03,  6.70855772e-03,\n",
       "       -8.21993779e-03, -2.54573878e-02, -3.41272578e-02, -4.62015206e-03,\n",
       "       -1.03185112e-02, -2.13341042e-02, -2.17125639e-02,  3.45263407e-02,\n",
       "        3.64461914e-02, -2.50899140e-02,  1.94045864e-02,  1.89810339e-02,\n",
       "        4.44756784e-02, -1.01772172e-03,  6.38390481e-02, -4.88876514e-02,\n",
       "        2.68849451e-03,  3.41418870e-02,  5.95646389e-02, -1.78531581e-03,\n",
       "        2.17234492e-02,  4.75256443e-02,  2.64142044e-02,  1.44468509e-02,\n",
       "       -1.58331096e-02, -2.75751087e-03,  2.58850027e-02,  2.66581252e-02,\n",
       "       -3.29117961e-02,  1.56424809e-02,  6.35205358e-02, -1.65103450e-02,\n",
       "        6.75751781e-03,  3.43154632e-02, -8.33553001e-02, -2.15553325e-02,\n",
       "       -9.91054531e-03, -5.64505011e-02,  6.60363305e-03, -1.37645006e-02,\n",
       "       -4.16488834e-02,  2.32809354e-02,  9.33220796e-03, -3.05639440e-03,\n",
       "       -1.71474423e-02, -2.11735740e-02, -2.73283906e-02, -1.27584087e-02,\n",
       "       -4.92479485e-05,  8.66628624e-03, -4.29726541e-02,  5.69035008e-04,\n",
       "       -3.90634313e-02, -1.14897769e-02,  6.89248219e-02,  2.06043180e-02,\n",
       "       -5.10899583e-03, -3.32521424e-02,  9.41237137e-02,  2.14948729e-02,\n",
       "        4.36880775e-02, -1.10364789e-02,  2.50744522e-02, -1.02218203e-02,\n",
       "       -1.44289527e-02,  1.71322152e-02, -5.07591628e-02, -2.84154853e-03,\n",
       "       -6.23462796e-02, -1.68698020e-02,  1.13717858e-02,  3.16562434e-03,\n",
       "       -4.25687097e-02, -4.94773053e-02,  8.40964615e-02,  7.30674306e-04,\n",
       "       -7.62321576e-02, -8.08312092e-03, -6.38485104e-02,  6.23142859e-03,\n",
       "       -6.65649325e-02,  3.45914364e-02,  1.93539411e-02,  1.05748437e-02,\n",
       "        6.06726669e-03,  2.92328894e-02, -4.24625166e-02,  1.70929711e-02,\n",
       "        6.69758022e-02, -7.82421082e-02, -2.56719775e-02, -1.25769237e-02,\n",
       "       -2.07150485e-02, -1.44397365e-02,  2.24479213e-02,  8.12790415e-04,\n",
       "       -2.30364334e-02, -1.00449268e-02,  1.68006886e-02, -8.27947166e-03,\n",
       "       -8.95914994e-03, -4.99347858e-02,  8.77987221e-03, -1.40894316e-02,\n",
       "        2.15154979e-02,  1.60865393e-02, -4.32761386e-03,  2.96334680e-02,\n",
       "       -1.81924161e-02, -8.92419834e-03,  3.93343484e-03,  4.39312831e-02,\n",
       "        5.07198237e-02, -2.79976092e-02,  6.93289712e-02,  2.40696501e-02,\n",
       "       -4.26816605e-02,  1.69535354e-02,  2.40890794e-02,  1.45840496e-02,\n",
       "        5.26947528e-02, -1.72672663e-02, -7.82459509e-04, -2.44506579e-02,\n",
       "        1.47009185e-02,  4.09016497e-02,  2.31351368e-02, -9.27793831e-02,\n",
       "       -3.15664932e-02,  6.75973855e-03,  3.68096605e-02, -2.13384591e-02,\n",
       "       -1.21394033e-02, -5.56081571e-02, -1.94428489e-02,  4.88477154e-03,\n",
       "       -1.92080764e-03, -5.84013686e-02, -4.72957455e-02, -6.46709464e-03,\n",
       "        1.45572061e-02,  2.44667605e-02,  9.50115174e-03, -6.58090264e-02,\n",
       "       -9.25837830e-02,  2.79770046e-03, -4.72670831e-02, -4.71502021e-02,\n",
       "        3.47478688e-02, -2.13036556e-02,  3.68678644e-02, -1.39256911e-02,\n",
       "       -4.07598056e-02,  1.06460512e-01,  2.15989202e-02, -8.01495686e-02,\n",
       "       -7.98491389e-02, -1.27654402e-02,  3.64464931e-02, -2.89540105e-02,\n",
       "       -3.08991894e-02,  2.32358072e-02, -8.00713524e-03, -7.50880018e-02,\n",
       "       -4.35848013e-02, -5.66319190e-02,  3.40569718e-03, -2.86410265e-02,\n",
       "        6.41761497e-02,  3.11382618e-02, -4.06176411e-02, -7.12165656e-03,\n",
       "        8.70682858e-03, -5.80938384e-02,  6.54487759e-02, -3.89219932e-02,\n",
       "        5.68002872e-02, -3.75550166e-02, -4.45007533e-02, -2.49207346e-03,\n",
       "       -6.55738041e-02, -6.73922300e-02, -6.16171584e-02,  5.37670888e-02,\n",
       "       -1.76741052e-02,  1.34923523e-02, -1.88954193e-02,  9.60910134e-03,\n",
       "        6.33508638e-02,  5.55378152e-03, -2.81218719e-03, -5.09194136e-02,\n",
       "       -5.03837643e-03,  2.44047493e-02, -4.86795278e-03, -2.60613281e-02,\n",
       "       -1.73134077e-02, -3.18363160e-02,  2.64154132e-02, -1.35053275e-02,\n",
       "        1.63954943e-02, -5.46275117e-02, -9.03723482e-03, -1.17572658e-02,\n",
       "       -6.01881417e-04,  1.54943820e-02, -4.17018719e-02,  2.56799888e-02,\n",
       "       -1.28812483e-02,  2.63563376e-02, -1.63648948e-02, -2.48654634e-02,\n",
       "        6.83060065e-02, -1.10762492e-02, -8.86231754e-03,  1.17652230e-02,\n",
       "       -4.64823842e-02,  4.35998477e-02, -9.88258328e-03, -1.45272876e-03,\n",
       "       -3.81557569e-02, -4.81919162e-02,  7.16136545e-02,  3.03445533e-02,\n",
       "       -1.76453975e-03, -6.43529138e-03, -2.03770362e-02, -2.82285921e-02,\n",
       "        6.07062802e-02, -1.47768026e-02,  6.94487467e-02,  3.52218784e-02,\n",
       "       -2.20680032e-02,  2.56672828e-03,  1.82896629e-02, -1.34139434e-02,\n",
       "       -3.29877883e-02,  6.86465427e-02, -8.80271569e-03, -9.77274869e-03,\n",
       "       -7.19159171e-02, -3.46992277e-02,  1.73757505e-02,  2.78786886e-02,\n",
       "       -1.14716841e-02,  2.41462048e-02, -2.38998123e-02,  3.39114666e-02,\n",
       "        2.88955886e-02, -2.25448813e-02, -3.02897319e-02,  3.92611995e-02,\n",
       "        5.23577519e-02,  1.79756768e-02,  2.19729189e-02,  3.48603874e-02,\n",
       "       -2.83223600e-03, -6.72653317e-03, -3.31720971e-02,  2.98512392e-02,\n",
       "        7.56077701e-03,  1.31716123e-02, -2.97631905e-03, -5.70811130e-33,\n",
       "       -3.80509123e-02, -3.16623114e-02, -9.48778260e-03,  3.78614925e-02,\n",
       "        3.46019082e-02, -1.84394587e-02,  2.54496373e-02,  3.30912210e-02,\n",
       "        2.27330308e-02, -4.36292915e-03, -6.79160189e-03,  4.87051159e-02,\n",
       "        3.07431556e-02, -2.48619020e-02,  2.57188082e-02,  2.78977435e-02,\n",
       "        3.20611298e-02,  8.69012401e-02,  1.54425837e-02, -1.78990923e-02,\n",
       "       -4.25925069e-02, -5.21405898e-02, -3.36067155e-02,  3.21253366e-03,\n",
       "        1.11497724e-02,  6.60051638e-03,  2.64068949e-03, -2.53874119e-02,\n",
       "        7.19858985e-03, -3.98473116e-03,  4.11321372e-02,  5.46340309e-02,\n",
       "       -1.07930498e-02,  8.11833516e-02, -3.12562496e-03,  5.73426150e-02,\n",
       "       -4.59357761e-02, -2.06821375e-02,  2.38380805e-02,  6.21537194e-02,\n",
       "       -1.33593203e-02, -2.26839520e-02,  8.64603072e-02, -3.95820662e-03,\n",
       "       -9.00167413e-03, -2.66624987e-02,  6.16095141e-02, -5.05195092e-03,\n",
       "        7.53134042e-02,  6.89153885e-03, -4.21270654e-02, -1.00597925e-03,\n",
       "       -6.65679649e-02,  3.00322659e-02, -7.27644470e-03, -7.17212970e-04,\n",
       "       -9.28911194e-03, -4.34596874e-02, -7.98469223e-03,  3.19854431e-02,\n",
       "        1.25607634e-02,  1.55433267e-02,  4.60264087e-02, -7.92038118e-05,\n",
       "       -2.70152669e-02,  3.65150650e-03,  3.65658775e-02,  5.04146218e-02,\n",
       "        3.12001221e-02,  4.24613617e-02,  8.31269659e-04,  3.28413732e-02,\n",
       "       -5.69479242e-02,  3.99193875e-02,  7.27808708e-03, -4.30167876e-02,\n",
       "       -2.44257413e-03, -4.08577658e-02,  4.03570849e-03, -6.58856556e-02,\n",
       "       -1.10568441e-02,  4.57109921e-02,  2.11418141e-03, -5.05882874e-02,\n",
       "        3.27953510e-02,  2.03283299e-02, -1.46882385e-02, -2.21633986e-02,\n",
       "       -1.44266011e-02, -3.65786836e-04,  3.82655524e-02, -1.46960709e-02,\n",
       "       -4.89107929e-02, -1.05909230e-02,  2.36378927e-02, -1.40958615e-02,\n",
       "       -7.25373160e-03, -6.78294664e-03, -4.75778542e-02,  1.97395962e-02,\n",
       "       -4.55502458e-02,  2.20281910e-02, -4.66148295e-02, -8.22541397e-03,\n",
       "        5.65046109e-02,  3.25221233e-02,  7.13572325e-03, -6.78855414e-03,\n",
       "       -3.57892998e-02, -4.17531542e-02, -2.23811194e-02,  1.55671118e-02,\n",
       "       -4.67596110e-03,  2.90886555e-02,  1.63342264e-02, -4.89140861e-03,\n",
       "        4.36895825e-02, -1.36232581e-02, -6.67338818e-02, -5.67200854e-02,\n",
       "       -2.42129136e-02, -1.49621088e-02, -6.70798272e-02, -3.80461547e-03,\n",
       "        8.46560206e-03, -3.17309387e-02,  1.21465074e-02,  3.32485326e-02,\n",
       "       -1.39469700e-02, -6.41508847e-02, -1.46747204e-02,  2.96846945e-02,\n",
       "        2.19403702e-07, -2.10174099e-02,  5.85861318e-02,  2.46251607e-03,\n",
       "        6.63666725e-02, -4.03289823e-03,  2.52896063e-02, -2.17929855e-02,\n",
       "        1.58693343e-02, -8.64692993e-05,  3.77422720e-02, -6.97718039e-02,\n",
       "        3.90548483e-02, -1.47047313e-02, -5.25772609e-02, -3.13705718e-03,\n",
       "       -1.44915944e-02,  4.88454103e-03,  3.74173298e-02,  6.53501414e-03,\n",
       "       -1.14912177e-02,  7.18391389e-02,  2.73808930e-03,  5.86540736e-02,\n",
       "        1.22259194e-02,  3.42476391e-03, -3.16530988e-02, -2.10776385e-02,\n",
       "       -7.29876512e-04,  7.71138147e-02,  7.94971809e-02, -7.31388554e-02,\n",
       "        2.38037389e-02,  2.94722412e-02,  7.88793936e-02, -1.79399326e-02,\n",
       "       -9.66326818e-02,  5.78399599e-02,  9.25918892e-02,  2.60814588e-04,\n",
       "        9.80608761e-02,  1.26945386e-02, -4.04327828e-03, -3.99733260e-02,\n",
       "       -4.17980878e-03,  8.02018493e-03,  2.34414749e-02,  3.59380208e-02,\n",
       "        5.20488210e-02, -5.25575550e-03, -6.59703314e-02, -3.95181589e-02,\n",
       "       -1.26960167e-05,  4.12586108e-02, -8.67932197e-03,  2.41091996e-02,\n",
       "       -5.67298979e-02, -7.11888522e-02,  2.41271071e-02,  9.12850909e-03,\n",
       "        4.15410139e-02, -3.44170220e-02, -5.25238402e-02, -1.96929509e-03,\n",
       "        2.09436677e-02,  5.44394255e-02,  4.93962094e-02, -7.67184841e-03,\n",
       "        1.55831773e-34,  2.51676999e-02,  4.98388847e-03, -4.37566601e-02,\n",
       "       -8.83559696e-03,  6.64050803e-02, -1.19425207e-02,  1.97270773e-02,\n",
       "       -1.57919358e-02,  9.68530402e-03,  9.80035663e-02, -5.09534217e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "pinecone_index = pc.Index(\"codebase-rag\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pg/wwfxmq4x1vx_t00m5pz1z4nr0000gp/T/ipykernel_89637/2416920381.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())\n",
      "/var/folders/pg/wwfxmq4x1vx_t00m5pz1z4nr0000gp/T/ipykernel_89637/2416920381.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())\n"
     ]
    }
   ],
   "source": [
    "vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pg/wwfxmq4x1vx_t00m5pz1z4nr0000gp/T/ipykernel_89637/1217438980.py:14: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding=HuggingFaceEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for file in file_content:\n",
    "    doc = Document(\n",
    "        page_content=f\"{file['name']}\\n{file['content']}\",\n",
    "        metadata={\"source\": file['name']}\n",
    "    )\n",
    "\n",
    "    documents.append(doc)\n",
    "\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    index_name=\"codebase-rag\",\n",
    "    namespace=\"https://github.com/CoderAgent/SecureAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How are python files parsed?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.29357567e-02, -6.24647066e-02, -2.87437793e-02,  1.83179360e-02,\n",
       "       -4.33846377e-04,  4.03238945e-02, -7.76650757e-03, -2.74391146e-03,\n",
       "        2.53445171e-02, -8.10819641e-02, -8.44585430e-03, -6.59265695e-03,\n",
       "        4.16187905e-02,  3.98627371e-02,  2.82911919e-02,  2.84344591e-02,\n",
       "        2.65302937e-02, -2.60126553e-02,  4.16299328e-02,  3.92820574e-02,\n",
       "       -5.15580177e-02,  5.83349727e-02,  5.88832889e-03,  3.46064903e-02,\n",
       "       -2.46877363e-03,  2.72808708e-02,  1.07212616e-02,  4.55761366e-02,\n",
       "       -1.69188995e-02, -4.85301316e-02, -3.02425176e-02, -3.29698063e-02,\n",
       "        2.46010330e-02,  3.23601812e-02,  1.16030503e-06,  9.71374661e-03,\n",
       "       -3.70800272e-02,  1.84201207e-02, -1.39834406e-02,  4.25722934e-02,\n",
       "        6.78141117e-02, -6.66247159e-02,  2.11651698e-02, -1.11715030e-03,\n",
       "       -1.80114824e-02, -7.90140033e-02,  5.93152903e-02, -5.23733683e-02,\n",
       "        5.63013516e-02,  4.31279950e-02,  7.77091598e-03, -2.30586529e-02,\n",
       "       -2.94572208e-02,  2.77148690e-02, -4.47696187e-02,  9.26125608e-03,\n",
       "        2.05622688e-02,  1.89164821e-02, -1.17682200e-03, -5.75425066e-02,\n",
       "        6.23189397e-02, -6.24255724e-02, -1.03146033e-02,  2.10920069e-02,\n",
       "       -2.46261386e-03,  1.55238668e-03, -2.58620903e-02, -8.25273395e-02,\n",
       "       -1.62820350e-02, -1.60427988e-02, -9.51343589e-03, -3.61014903e-02,\n",
       "       -3.72008532e-02, -3.06943711e-02, -3.55278840e-03, -4.09894362e-02,\n",
       "       -4.44806218e-02,  5.48976026e-02,  1.24197053e-02,  2.40757074e-02,\n",
       "        6.85857385e-02, -2.74425503e-02,  2.51468085e-02, -3.05046216e-02,\n",
       "       -9.07214656e-02,  8.37038234e-02, -1.79595072e-02, -4.08667810e-02,\n",
       "       -3.23813148e-02,  4.20789830e-02, -1.16966795e-02, -5.89074902e-02,\n",
       "        5.40730804e-02, -1.61599144e-02,  3.99519876e-02, -1.29147703e-02,\n",
       "       -9.99882631e-03, -1.50061995e-02,  2.09495495e-03,  8.62604193e-03,\n",
       "       -3.09340805e-02,  1.84233487e-02, -4.64415662e-02,  1.31826838e-02,\n",
       "        3.10081374e-02,  6.74636522e-03,  2.38200482e-02,  3.98994721e-02,\n",
       "        2.22703889e-02,  6.18383987e-03, -8.69598240e-03, -2.51342542e-02,\n",
       "       -3.50810736e-02, -2.34969370e-02,  1.84799638e-02,  1.21879606e-02,\n",
       "        3.25379930e-02,  1.41922571e-02,  5.00620343e-03,  3.89296003e-02,\n",
       "       -3.72823998e-02, -2.71471478e-02,  2.89376546e-02,  3.11495848e-02,\n",
       "       -2.57724021e-02,  3.29544097e-02,  2.84122992e-02, -4.72985953e-03,\n",
       "       -2.35042647e-02, -1.74627453e-02,  2.09165714e-03,  1.12597244e-02,\n",
       "        1.37390047e-02, -1.92198511e-02, -2.42439890e-03,  4.58117910e-02,\n",
       "        2.00344305e-02,  2.40761600e-02,  3.83133665e-02,  4.86851018e-03,\n",
       "        4.09107842e-02,  1.27002830e-02,  1.02278087e-02, -3.14175934e-02,\n",
       "       -1.90840848e-02,  6.56972602e-02,  2.11260691e-02, -5.34587875e-02,\n",
       "       -1.36227645e-02, -8.12979508e-03, -7.64817521e-02,  1.93470009e-02,\n",
       "       -9.81905311e-03, -3.36908959e-02, -3.25244106e-02, -4.96620573e-02,\n",
       "       -2.79479264e-03, -6.36658072e-02,  2.75942609e-02, -3.15714404e-02,\n",
       "       -1.51134061e-03, -8.72665718e-02,  8.31872877e-03, -6.17535003e-02,\n",
       "       -2.22608745e-02, -3.06138676e-03,  1.73493028e-02, -2.11431948e-03,\n",
       "        3.26970182e-02, -1.72854476e-02, -3.01894136e-02,  3.36199105e-02,\n",
       "       -6.67415652e-03, -1.01258149e-02, -9.62471142e-02,  8.46371129e-02,\n",
       "       -1.96113922e-02, -2.88200155e-02,  7.15460181e-02,  5.81254475e-02,\n",
       "        4.77788188e-02,  7.82424659e-02, -1.38306273e-02, -2.19270531e-02,\n",
       "        3.99027728e-02, -2.27789078e-02, -1.18104359e-02,  3.33289653e-02,\n",
       "        5.07154204e-02,  1.52401847e-03, -6.07940815e-02,  4.19562161e-02,\n",
       "        5.17812744e-02, -4.86721843e-02, -3.48878349e-03, -3.31364870e-02,\n",
       "       -2.18327083e-02,  8.91788211e-03,  2.30655205e-02, -2.47854460e-02,\n",
       "       -1.22968024e-02, -9.04862024e-03, -4.89094108e-02,  6.31100684e-02,\n",
       "        3.78329530e-02,  3.73009220e-02,  2.12741811e-02, -5.94596565e-02,\n",
       "       -5.44957370e-02, -1.80757530e-02, -2.94007696e-02,  2.36047767e-02,\n",
       "        1.18150385e-02, -1.68413928e-04, -2.93773804e-02, -3.20025645e-02,\n",
       "        1.70538444e-02,  1.84272118e-02, -3.88709307e-02, -4.22034897e-02,\n",
       "       -6.89315191e-03,  3.49993668e-02, -1.63522959e-02,  5.40450998e-02,\n",
       "       -6.86172582e-03,  8.39832064e-05, -2.28055120e-02,  1.84533298e-02,\n",
       "       -5.23327403e-02,  5.85398376e-02, -6.05440438e-02,  4.67985421e-02,\n",
       "        2.97169648e-02,  3.79332490e-02,  1.08826034e-01, -1.34921512e-02,\n",
       "       -3.65445800e-02,  5.36772646e-02,  5.20055778e-02,  1.73453502e-02,\n",
       "       -2.86380593e-02,  2.51034033e-02,  7.99697042e-02,  8.45407695e-03,\n",
       "       -8.40063021e-03,  1.62151437e-02,  3.37266177e-02,  1.04514528e-02,\n",
       "        2.85697393e-02,  1.27325123e-02,  5.88390939e-02,  4.45223153e-02,\n",
       "       -5.37755117e-02,  3.13246213e-02, -1.95733979e-02,  5.36993556e-02,\n",
       "        1.35699827e-02,  5.48132174e-02, -2.60083545e-02, -8.54836330e-02,\n",
       "        5.50539345e-02,  4.39010095e-03, -3.81788611e-02, -6.26972970e-03,\n",
       "       -2.66886409e-02,  3.93094756e-02, -3.83768938e-02, -2.26172549e-03,\n",
       "        1.01410439e-02, -1.67041067e-02,  1.52516775e-02,  3.10032722e-02,\n",
       "       -5.70694171e-02,  1.19964918e-02,  2.10933108e-03,  1.90200079e-02,\n",
       "       -5.28422222e-02, -3.40813063e-02, -5.73632249e-04,  1.67012140e-02,\n",
       "        3.37425210e-02, -1.69162173e-02, -4.27705161e-02, -4.10331264e-02,\n",
       "       -3.51206064e-02,  5.66735789e-02,  1.48051418e-02, -5.41751385e-02,\n",
       "       -3.35608684e-02,  3.00901178e-02, -6.50477968e-03, -3.19957957e-02,\n",
       "        1.81440692e-02, -5.37339710e-02,  4.36228747e-03, -5.37621789e-02,\n",
       "        1.50755709e-02,  2.33239606e-02, -1.38578555e-02, -3.34761757e-03,\n",
       "        5.32320924e-02, -2.44215187e-02, -1.18555920e-02, -1.05982386e-02,\n",
       "        1.77718997e-02, -1.37670301e-02,  1.44016407e-02, -6.25981688e-02,\n",
       "       -4.68251854e-02,  6.42346367e-02,  5.49899973e-03,  3.26832235e-02,\n",
       "       -1.80161316e-02,  2.26008501e-02, -3.93174849e-02, -2.66568903e-02,\n",
       "       -1.59493200e-02, -1.35791432e-02,  4.52421606e-02,  1.70296580e-02,\n",
       "        1.14436252e-02, -1.96962487e-02,  7.43183121e-02, -4.17754352e-02,\n",
       "       -5.52875409e-03, -2.08973512e-02, -2.74067111e-02, -2.89906356e-02,\n",
       "        4.83474582e-02,  5.47394492e-02, -4.23560366e-02,  1.28818611e-02,\n",
       "       -6.16976805e-02,  1.15629621e-02,  1.32414335e-02,  2.89796460e-02,\n",
       "        2.16499791e-02, -2.65880041e-02,  2.28246227e-02,  5.02933329e-03,\n",
       "       -4.52499883e-03,  2.87271030e-02,  2.32656077e-02,  1.61632765e-02,\n",
       "       -3.92807946e-02,  3.48354839e-02, -6.54506497e-03, -3.81123014e-02,\n",
       "        1.66637246e-02,  5.22399098e-02,  5.42763993e-02,  1.46359112e-03,\n",
       "        4.05131839e-02,  2.79733874e-02, -1.03878155e-02, -1.23620424e-02,\n",
       "       -8.55705440e-02, -3.98034267e-02, -1.03295362e-02, -3.06917238e-03,\n",
       "        1.12385787e-02, -3.92905325e-02, -2.37615760e-02,  3.73438448e-02,\n",
       "       -6.09336700e-03,  8.03027581e-03,  3.26007344e-02,  1.72168557e-02,\n",
       "       -3.07254735e-02,  5.34811132e-02, -5.66900186e-02, -3.31042185e-02,\n",
       "        3.15090339e-03,  4.01630476e-02,  3.73294391e-02,  4.30786610e-02,\n",
       "        2.35213283e-02, -6.31922409e-02, -4.67105620e-02,  1.52615050e-03,\n",
       "        2.12465171e-02, -2.98658498e-02, -1.75439694e-03, -3.56526189e-02,\n",
       "        3.30406837e-02,  1.38598867e-02,  2.68206988e-02,  1.34316748e-02,\n",
       "        3.49891782e-02,  5.81625439e-02,  8.51072557e-03,  3.70358787e-02,\n",
       "       -3.87328900e-02,  2.32067425e-02, -5.87725416e-02, -1.05009377e-02,\n",
       "        5.82163036e-03,  5.60880825e-02, -1.43478354e-02,  3.23774293e-02,\n",
       "        3.04520037e-02, -1.76104959e-02,  4.66958396e-02, -3.46061564e-03,\n",
       "        3.63383517e-02,  1.65876136e-05,  5.00890985e-02,  2.17342842e-02,\n",
       "       -5.97168095e-02,  2.37415116e-02,  4.31473590e-02, -3.18265222e-02,\n",
       "        1.77777540e-02,  3.15743033e-04, -1.66758115e-03,  6.83110729e-02,\n",
       "       -2.12966275e-04,  4.88594472e-02, -4.54999171e-02, -2.93329172e-02,\n",
       "       -1.74761210e-02, -4.37862761e-02,  3.16109732e-02, -3.79561521e-02,\n",
       "       -4.94188294e-02,  3.52672599e-02, -1.74174886e-02, -3.25312801e-02,\n",
       "        2.89960857e-02,  4.52595875e-02,  7.38305971e-02, -8.94752592e-02,\n",
       "       -7.83320367e-02, -2.74328911e-03, -1.87086519e-02, -2.89897304e-02,\n",
       "        4.76685353e-02, -9.56919696e-03, -4.72693816e-02, -4.63580750e-02,\n",
       "        1.19096115e-02,  2.20620222e-02, -9.29960310e-02, -3.78828049e-02,\n",
       "       -4.13095020e-02, -9.80007462e-03,  3.03514060e-02, -4.30159494e-02,\n",
       "        9.04981140e-03,  7.71178752e-02,  3.58079970e-02, -5.53936772e-02,\n",
       "       -1.05007038e-01,  1.63989272e-02,  2.27310602e-02, -1.85960084e-02,\n",
       "       -3.08086518e-02, -2.71823984e-02, -1.11027909e-02,  6.46361187e-02,\n",
       "       -4.28788066e-02,  1.08859781e-02, -2.96999421e-02,  2.61760652e-02,\n",
       "       -8.78905691e-03, -1.43633187e-02,  6.00802563e-02, -6.33777454e-02,\n",
       "        2.11548358e-02,  1.00529101e-02,  8.03635921e-03,  2.75852680e-02,\n",
       "       -1.75669231e-02,  3.40636708e-02, -3.72855105e-02,  2.70871189e-03,\n",
       "       -2.25255340e-02, -1.47844879e-02, -6.94794804e-02,  2.88431775e-02,\n",
       "        1.13193177e-01,  9.42973606e-03,  5.81743009e-02, -5.44003285e-02,\n",
       "        2.34901588e-02,  1.37523012e-02,  1.88617545e-04,  2.38734344e-03,\n",
       "       -6.18971810e-02, -2.54469439e-02,  6.11821713e-04,  1.65087846e-03,\n",
       "        3.84528376e-02,  3.83725278e-02, -2.18702815e-02,  4.91975993e-02,\n",
       "       -1.41742826e-02,  8.67886394e-02,  4.70688716e-02, -1.33780735e-02,\n",
       "        2.43281405e-02,  2.13124347e-03, -7.80032482e-03, -1.94361191e-02,\n",
       "       -3.51535566e-02,  1.94780137e-02,  6.13574916e-03,  6.65925220e-02,\n",
       "       -5.17740287e-02, -1.71758104e-02,  1.49639426e-02,  3.49694751e-02,\n",
       "       -2.75514070e-02, -2.56296676e-02,  3.78721133e-02, -9.43364017e-03,\n",
       "       -1.71610061e-02, -1.16129806e-02,  5.20717315e-02, -3.90320681e-02,\n",
       "        1.38096232e-02, -1.07297786e-02,  6.45306930e-02, -3.71250033e-04,\n",
       "        1.66364647e-02, -5.59038296e-02, -1.95199419e-02, -4.32062820e-02,\n",
       "       -1.28882118e-02,  1.61057394e-02, -1.22971199e-02,  5.02005704e-02,\n",
       "        2.27776319e-02, -5.06646074e-02,  1.50559619e-02, -6.99814176e-03,\n",
       "       -1.79000702e-02,  2.83965357e-02, -1.61608849e-02,  7.43089095e-02,\n",
       "        5.80932386e-03, -3.79784070e-02, -3.01361717e-02,  4.63075936e-02,\n",
       "       -1.88925918e-02, -8.24493617e-02, -2.90479828e-02,  4.06599380e-02,\n",
       "       -2.34173909e-02,  1.74947828e-02, -2.53150426e-02,  5.00645041e-02,\n",
       "       -2.05936730e-02,  3.87833890e-04, -3.11556607e-02, -3.36270767e-33,\n",
       "       -3.64931300e-02, -9.84393153e-03, -1.27960481e-02,  3.68757471e-02,\n",
       "        7.21486136e-02, -2.93234345e-02, -1.90743338e-02,  1.27501991e-02,\n",
       "       -2.75648851e-02, -3.92989926e-02,  1.47465197e-02,  5.34270424e-03,\n",
       "        6.80221198e-03, -5.00148237e-02, -3.25023793e-02, -3.29954224e-03,\n",
       "       -4.41080332e-02,  4.25063632e-02, -2.22562887e-02, -4.24127206e-02,\n",
       "        4.97954004e-02,  1.96501967e-02,  7.10431933e-02, -1.33237406e-03,\n",
       "       -1.59612708e-02, -3.19576077e-02,  7.12696975e-03, -3.98079641e-02,\n",
       "       -1.02064724e-03,  5.80802783e-02,  4.18782188e-03, -5.21540269e-02,\n",
       "        2.75403671e-02,  9.57600307e-03, -3.45046856e-02,  1.75636783e-02,\n",
       "       -1.15363235e-02,  2.99454425e-02, -1.88699570e-02,  2.50331289e-03,\n",
       "       -9.36549716e-03,  3.24894092e-03,  9.50336084e-02, -2.04751939e-02,\n",
       "        9.50888637e-03,  3.28423418e-02, -3.02088931e-02, -1.78127717e-02,\n",
       "       -6.97344309e-03,  3.42990831e-02,  4.33419133e-03,  1.85266417e-02,\n",
       "       -1.02243256e-02,  2.98240203e-02,  5.75671047e-02, -1.29386848e-02,\n",
       "       -3.49400565e-02,  2.46348940e-02,  1.52298883e-02,  8.63340031e-03,\n",
       "        3.54273096e-02,  3.50684710e-02, -1.01720421e-02, -6.12878129e-02,\n",
       "       -1.37159443e-02, -1.14262905e-02,  4.86185178e-02,  1.04867807e-03,\n",
       "        1.53522333e-02,  3.61608937e-02, -2.83763390e-02,  1.60172873e-03,\n",
       "       -5.29458076e-02, -1.93459038e-02, -2.98061389e-02,  1.66549580e-03,\n",
       "       -8.09495896e-03,  4.39761486e-03,  4.46844995e-02,  5.34071540e-03,\n",
       "       -6.30121753e-02,  1.23348450e-02,  1.99630149e-02,  3.15868994e-03,\n",
       "       -4.30848077e-02,  1.51274903e-02, -2.88297366e-02, -2.31992882e-02,\n",
       "       -2.59096995e-02, -3.08083557e-02, -3.88281867e-02,  3.47705260e-02,\n",
       "        1.39503377e-02, -6.15115510e-03,  1.83904208e-02,  8.75677168e-03,\n",
       "       -1.10230863e-01,  1.99391022e-02, -1.60657465e-02, -5.22737857e-04,\n",
       "        1.18507026e-02, -1.24846306e-02, -2.22272873e-02, -1.16752110e-01,\n",
       "        5.94093539e-02,  2.55837142e-02, -5.00593483e-02,  2.07637269e-02,\n",
       "       -2.28052791e-02, -1.17855547e-02, -1.86712127e-02,  1.88260339e-03,\n",
       "       -3.07054799e-02,  6.18604906e-02,  1.36793554e-02,  2.31921785e-02,\n",
       "       -4.05402109e-03, -5.55822477e-02, -8.11266620e-03, -2.45206542e-02,\n",
       "       -1.45674255e-02,  3.35017703e-02,  1.73942801e-02, -2.79465280e-02,\n",
       "       -8.23854804e-02, -3.22012566e-02, -2.29693186e-02, -1.69347785e-02,\n",
       "        4.42385152e-02,  8.61014202e-02, -1.80195144e-03,  5.69039695e-02,\n",
       "        1.80935473e-07,  5.13121635e-02,  3.70614752e-02,  6.87918290e-02,\n",
       "        4.76195812e-02,  1.33520197e-02,  4.64612879e-02, -7.49314576e-02,\n",
       "        1.45223327e-02,  9.45928879e-03, -5.34115732e-02, -1.06149586e-02,\n",
       "       -3.35417576e-02, -6.11188705e-04,  1.55675309e-02,  6.57156855e-03,\n",
       "        5.05602621e-02, -2.86132041e-02, -2.96778139e-02, -3.09103429e-02,\n",
       "        1.43582588e-02,  1.43137183e-02,  4.98098582e-02,  3.52616725e-03,\n",
       "       -8.30852892e-03, -1.33262509e-02, -3.71968746e-02, -1.30646201e-02,\n",
       "       -5.25354953e-05,  3.71610560e-02,  5.53412363e-04, -4.29663174e-02,\n",
       "       -2.59780381e-02,  6.19658458e-05, -9.12475865e-03, -1.68120787e-02,\n",
       "       -3.33810523e-02, -4.00934787e-03,  8.06671008e-02,  8.46772362e-03,\n",
       "        6.66167960e-02, -4.38743737e-03, -2.76704635e-02, -1.04519194e-02,\n",
       "       -2.51315869e-02,  1.76670763e-03,  2.08077617e-02, -1.91202257e-02,\n",
       "       -4.90712039e-02, -1.00785540e-02,  4.09476236e-02, -3.99245247e-02,\n",
       "        2.54176650e-02,  2.23035049e-02,  4.49331999e-02, -7.68014137e-03,\n",
       "       -1.72685701e-02,  7.24879839e-03,  3.24925445e-02, -1.36583671e-02,\n",
       "       -8.47304165e-02, -1.55934393e-02, -2.89407279e-02, -4.69765998e-02,\n",
       "       -2.00475566e-02,  4.18929830e-02,  2.60194996e-03,  2.67458744e-02,\n",
       "        1.31175366e-34,  6.73724455e-04, -3.93718146e-02,  1.87982265e-02,\n",
       "       -6.08653156e-03, -3.60376425e-02,  2.95597780e-02,  4.36338224e-03,\n",
       "        2.76056714e-02, -3.13765518e-02, -6.78376062e-03,  6.06068643e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_query_embedding = get_huggingface_embeddings(query)\n",
    "\n",
    "raw_query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=\"https://github.com/CoderAgent/SecureAgent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '1e98ddff-6a6e-4446-b7e6-729dae80c230',\n",
       "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
       "                           'text': 'src/context/language/python-parser.ts\\n'\n",
       "                                   'import { AbstractParser, EnclosingContext '\n",
       "                                   '} from \"../../constants\";\\n'\n",
       "                                   'export class PythonParser implements '\n",
       "                                   'AbstractParser {\\n'\n",
       "                                   '  findEnclosingContext(\\n'\n",
       "                                   '    file: string,\\n'\n",
       "                                   '    lineStart: number,\\n'\n",
       "                                   '    lineEnd: number\\n'\n",
       "                                   '  ): EnclosingContext {\\n'\n",
       "                                   '    // TODO: Implement this method for '\n",
       "                                   'Python\\n'\n",
       "                                   '    return null;\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '  dryRun(file: string): { valid: boolean; '\n",
       "                                   'error: string } {\\n'\n",
       "                                   '    // TODO: Implement this method for '\n",
       "                                   'Python\\n'\n",
       "                                   '    return { valid: false, error: \"Not '\n",
       "                                   'implemented yet\" };\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '}\\n'},\n",
       "              'score': 0.473748982,\n",
       "              'values': []},\n",
       "             {'id': 'bb6765ae-3f84-4a72-8d7b-c902fb517354',\n",
       "              'metadata': {'source': 'src/context/language/javascript-parser.ts',\n",
       "                           'text': 'src/context/language/javascript-parser.ts\\n'\n",
       "                                   'import { AbstractParser, EnclosingContext '\n",
       "                                   '} from \"../../constants\";\\n'\n",
       "                                   'import * as parser from \"@babel/parser\";\\n'\n",
       "                                   'import traverse, { NodePath, Node } from '\n",
       "                                   '\"@babel/traverse\";\\n'\n",
       "                                   '\\n'\n",
       "                                   'const processNode = (\\n'\n",
       "                                   '  path: NodePath<Node>,\\n'\n",
       "                                   '  lineStart: number,\\n'\n",
       "                                   '  lineEnd: number,\\n'\n",
       "                                   '  largestSize: number,\\n'\n",
       "                                   '  largestEnclosingContext: Node | null\\n'\n",
       "                                   ') => {\\n'\n",
       "                                   '  const { start, end } = path.node.loc;\\n'\n",
       "                                   '  if (start.line <= lineStart && lineEnd '\n",
       "                                   '<= end.line) {\\n'\n",
       "                                   '    const size = end.line - start.line;\\n'\n",
       "                                   '    if (size > largestSize) {\\n'\n",
       "                                   '      largestSize = size;\\n'\n",
       "                                   '      largestEnclosingContext = '\n",
       "                                   'path.node;\\n'\n",
       "                                   '    }\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '  return { largestSize, '\n",
       "                                   'largestEnclosingContext };\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export class JavascriptParser implements '\n",
       "                                   'AbstractParser {\\n'\n",
       "                                   '  findEnclosingContext(\\n'\n",
       "                                   '    file: string,\\n'\n",
       "                                   '    lineStart: number,\\n'\n",
       "                                   '    lineEnd: number\\n'\n",
       "                                   '  ): EnclosingContext {\\n'\n",
       "                                   '    const ast = parser.parse(file, {\\n'\n",
       "                                   '      sourceType: \"module\",\\n'\n",
       "                                   '      plugins: [\"jsx\", \"typescript\"], // '\n",
       "                                   'To allow JSX and TypeScript\\n'\n",
       "                                   '    });\\n'\n",
       "                                   '    let largestEnclosingContext: Node = '\n",
       "                                   'null;\\n'\n",
       "                                   '    let largestSize = 0;\\n'\n",
       "                                   '    traverse(ast, {\\n'\n",
       "                                   '      Function(path) {\\n'\n",
       "                                   '        ({ largestSize, '\n",
       "                                   'largestEnclosingContext } = processNode(\\n'\n",
       "                                   '          path,\\n'\n",
       "                                   '          lineStart,\\n'\n",
       "                                   '          lineEnd,\\n'\n",
       "                                   '          largestSize,\\n'\n",
       "                                   '          largestEnclosingContext\\n'\n",
       "                                   '        ));\\n'\n",
       "                                   '      },\\n'\n",
       "                                   '      TSInterfaceDeclaration(path) {\\n'\n",
       "                                   '        ({ largestSize, '\n",
       "                                   'largestEnclosingContext } = processNode(\\n'\n",
       "                                   '          path,\\n'\n",
       "                                   '          lineStart,\\n'\n",
       "                                   '          lineEnd,\\n'\n",
       "                                   '          largestSize,\\n'\n",
       "                                   '          largestEnclosingContext\\n'\n",
       "                                   '        ));\\n'\n",
       "                                   '      },\\n'\n",
       "                                   '    });\\n'\n",
       "                                   '    return {\\n'\n",
       "                                   '      enclosingContext: '\n",
       "                                   'largestEnclosingContext,\\n'\n",
       "                                   '    } as EnclosingContext;\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '\\n'\n",
       "                                   '  dryRun(file: string): { valid: boolean; '\n",
       "                                   'error: string } {\\n'\n",
       "                                   '    try {\\n'\n",
       "                                   '      const ast = parser.parse(file, {\\n'\n",
       "                                   '        sourceType: \"module\",\\n'\n",
       "                                   '        plugins: [\"jsx\", \"typescript\"], // '\n",
       "                                   'To allow JSX and TypeScript\\n'\n",
       "                                   '      });\\n'\n",
       "                                   '      return {\\n'\n",
       "                                   '        valid: true,\\n'\n",
       "                                   '        error: \"\",\\n'\n",
       "                                   '      };\\n'\n",
       "                                   '    } catch (exc) {\\n'\n",
       "                                   '      return {\\n'\n",
       "                                   '        valid: false,\\n'\n",
       "                                   '        error: exc,\\n'\n",
       "                                   '      };\\n'\n",
       "                                   '    }\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '}\\n'},\n",
       "              'score': 0.166329414,\n",
       "              'values': []},\n",
       "             {'id': '5b9471a8-6349-48a6-bb35-2ecfcafdd151',\n",
       "              'metadata': {'source': 'src/prompts.ts',\n",
       "                           'text': 'src/prompts.ts\\n'\n",
       "                                   'import { encode, encodeChat } from '\n",
       "                                   '\"gpt-tokenizer\";\\n'\n",
       "                                   'import type { ChatCompletionMessageParam } '\n",
       "                                   'from '\n",
       "                                   '\"groq-sdk/resources/chat/completions\";\\n'\n",
       "                                   'import type { PRFile } from '\n",
       "                                   '\"./constants\";\\n'\n",
       "                                   'import {\\n'\n",
       "                                   '  rawPatchStrategy,\\n'\n",
       "                                   '  smarterContextPatchStrategy,\\n'\n",
       "                                   '} from \"./context/review\";\\n'\n",
       "                                   'import { GROQ_MODEL, type GroqChatModel } '\n",
       "                                   'from \"./llms/groq\";\\n'\n",
       "                                   '\\n'\n",
       "                                   'const ModelsToTokenLimits: '\n",
       "                                   'Record<GroqChatModel, number> = {\\n'\n",
       "                                   '  \"mixtral-8x7b-32768\": 32768,\\n'\n",
       "                                   '  \"gemma-7b-it\": 32768,\\n'\n",
       "                                   '  \"llama3-70b-8192\": 8192,\\n'\n",
       "                                   '  \"llama3-8b-8192\": 8192,\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const REVIEW_DIFF_PROMPT = `You are '\n",
       "                                   'PR-Reviewer, a language model designed to '\n",
       "                                   'review git pull requests.\\n'\n",
       "                                   'Your task is to provide constructive and '\n",
       "                                   'concise feedback for the PR, and also '\n",
       "                                   'provide meaningful code suggestions.\\n'\n",
       "                                   '\\n'\n",
       "                                   'Example PR Diff input:\\n'\n",
       "                                   \"'\\n\"\n",
       "                                   '## src/file1.py\\n'\n",
       "                                   '\\n'\n",
       "                                   '@@ -12,5 +12,5 @@ def func1():\\n'\n",
       "                                   'code line that already existed in the '\n",
       "                                   'file...\\n'\n",
       "                                   'code line that already existed in the '\n",
       "                                   'file....\\n'\n",
       "                                   '-code line that was removed in the PR\\n'\n",
       "                                   '+new code line added in the PR\\n'\n",
       "                                   ' code line that already existed in the '\n",
       "                                   'file...\\n'\n",
       "                                   ' code line that already existed in the '\n",
       "                                   'file...\\n'\n",
       "                                   '\\n'\n",
       "                                   '@@ ... @@ def func2():\\n'\n",
       "                                   '...\\n'\n",
       "                                   '\\n'\n",
       "                                   '\\n'\n",
       "                                   '## src/file2.py\\n'\n",
       "                                   '...\\n'\n",
       "                                   \"'\\n\"\n",
       "                                   '\\n'\n",
       "                                   'The review should focus on new code added '\n",
       "                                   \"in the PR (lines starting with '+'), and \"\n",
       "                                   'not on code that already existed in the '\n",
       "                                   \"file (lines starting with '-', or without \"\n",
       "                                   'prefix).\\n'\n",
       "                                   '\\n'\n",
       "                                   '- ONLY PROVIDE CODE SUGGESTIONS\\n'\n",
       "                                   '- Focus on important suggestions like '\n",
       "                                   'fixing code problems, improving '\n",
       "                                   'performance, improving security, improving '\n",
       "                                   'readability\\n'\n",
       "                                   '- Avoid making suggestions that have '\n",
       "                                   'already been implemented in the PR code. '\n",
       "                                   'For example, if you want to add logs, or '\n",
       "                                   'change a variable to const, or anything '\n",
       "                                   \"else, make sure it isn't already in the PR \"\n",
       "                                   'code.\\n'\n",
       "                                   \"- Don't suggest adding docstring, type \"\n",
       "                                   'hints, or comments.\\n'\n",
       "                                   '- Suggestions should focus on improving '\n",
       "                                   'the new code added in the PR (lines '\n",
       "                                   \"starting with '+')\\n\"\n",
       "                                   '- Do not say things like without seeing '\n",
       "                                   'the full repo, or full code, or rest of '\n",
       "                                   'the codebase. Comment only on the code you '\n",
       "                                   'have!\\n'\n",
       "                                   '\\n'\n",
       "                                   'Make sure the provided code suggestions '\n",
       "                                   'are in the same programming language.\\n'\n",
       "                                   '\\n'\n",
       "                                   \"Don't repeat the prompt in the answer, and \"\n",
       "                                   \"avoid outputting the 'type' and \"\n",
       "                                   \"'description' fields.\\n\"\n",
       "                                   '\\n'\n",
       "                                   'Think through your suggestions and make '\n",
       "                                   'exceptional improvements.`;\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const XML_PR_REVIEW_PROMPT = `As '\n",
       "                                   'the PR-Reviewer AI model, you are tasked '\n",
       "                                   'to analyze git pull requests across any '\n",
       "                                   'programming language and provide '\n",
       "                                   'comprehensive and precise code '\n",
       "                                   'enhancements. Keep your focus on the new '\n",
       "                                   \"code modifications indicated by '+' lines \"\n",
       "                                   'in the PR. Your feedback should hunt for '\n",
       "                                   'code issues, opportunities for performance '\n",
       "                                   'enhancement, security improvements, and '\n",
       "                                   'ways to increase readability. \\n'\n",
       "                                   '\\n'\n",
       "                                   'Ensure your suggestions are novel and '\n",
       "                                   \"haven't been previously incorporated in \"\n",
       "                                   \"the '+' lines of the PR code. Refrain from \"\n",
       "                                   'proposing enhancements that add '\n",
       "                                   'docstrings, type hints, or comments. Your '\n",
       "                                   'recommendations should strictly target the '\n",
       "                                   \"'+' lines without suggesting the need for \"\n",
       "                                   'complete context such as the whole repo or '\n",
       "                                   'codebase.\\n'\n",
       "                                   '\\n'\n",
       "                                   'Your code suggestions should match the '\n",
       "                                   'programming language in the PR, steer '\n",
       "                                   'clear of needless repetition or inclusion '\n",
       "                                   \"of 'type' and 'description' fields.\\n\"\n",
       "                                   '\\n'\n",
       "                                   'Formulate thoughtful suggestions aimed at '\n",
       "                                   'strengthening performance, security, and '\n",
       "                                   'readability, and represent them in an XML '\n",
       "                                   'format utilizing the tags: <review>, '\n",
       "                                   '<code>, <suggestion>, <comment>, <type>, '\n",
       "                                   '<describe>, <filename>. While multiple '\n",
       "                                   'recommendations can be given, they should '\n",
       "                                   'all reside within one <review> tag.\\n'\n",
       "                                   '\\n'\n",
       "                                   'Also note, all your code suggestions '\n",
       "                                   'should follow the valid Markdown syntax '\n",
       "                                   'for GitHub, identifying the language '\n",
       "                                   \"they're written in, and should be enclosed \"\n",
       "                                   'within backticks (\\\\`\\\\`\\\\`). \\n'\n",
       "                                   '\\n'\n",
       "                                   \"Don't hesitate to add as many constructive \"\n",
       "                                   'suggestions as are relevant to really '\n",
       "                                   'improve the effectivity of the code.\\n'\n",
       "                                   '\\n'\n",
       "                                   'Example output:\\n'\n",
       "                                   '\\\\`\\\\`\\\\`\\n'\n",
       "                                   '<review>\\n'\n",
       "                                   '  <suggestion>\\n'\n",
       "                                   '    <describe>[Objective of the newly '\n",
       "                                   'incorporated code]</describe>\\n'\n",
       "                                   '    <type>[Category of the given '\n",
       "                                   'suggestion such as performance, security, '\n",
       "                                   'etc.]</type>\\n'\n",
       "                                   '    <comment>[Guidance on enhancing the '\n",
       "                                   'new code]</comment>\\n'\n",
       "                                   '    <code>\\n'\n",
       "                                   '    \\\\`\\\\`\\\\`[Programming Language]\\n'\n",
       "                                   '    [Equivalent code amendment in the same '\n",
       "                                   'language]\\n'\n",
       "                                   '    \\\\`\\\\`\\\\`\\n'\n",
       "                                   '    </code>\\n'\n",
       "                                   '    <filename>[name of relevant '\n",
       "                                   'file]</filename>\\n'\n",
       "                                   '  </suggestion>\\n'\n",
       "                                   '  <suggestion>\\n'\n",
       "                                   '  ...\\n'\n",
       "                                   '  </suggestion>\\n'\n",
       "                                   '  ...\\n'\n",
       "                                   '</review>\\n'\n",
       "                                   '\\\\`\\\\`\\\\`\\n'\n",
       "                                   '\\n'\n",
       "                                   \"Note: The 'comment' and 'describe' tags \"\n",
       "                                   'should elucidate the advice and why it’s '\n",
       "                                   \"given, while the 'code' tag hosts the \"\n",
       "                                   'recommended code snippet within proper '\n",
       "                                   \"GitHub Markdown syntax. The 'type' defines \"\n",
       "                                   \"the suggestion's category such as \"\n",
       "                                   'performance, security, readability, '\n",
       "                                   'etc.`;\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const PR_SUGGESTION_TEMPLATE = '\n",
       "                                   '`{COMMENT}\\n'\n",
       "                                   '{ISSUE_LINK}\\n'\n",
       "                                   '\\n'\n",
       "                                   '{CODE}\\n'\n",
       "                                   '`;\\n'\n",
       "                                   '\\n'\n",
       "                                   'const assignLineNumbers = (diff: string) '\n",
       "                                   '=> {\\n'\n",
       "                                   '  const lines = diff.split(\"\\\\n\");\\n'\n",
       "                                   '  let newLine = 0;\\n'\n",
       "                                   '  const lineNumbers = [];\\n'\n",
       "                                   '\\n'\n",
       "                                   '  for (const line of lines) {\\n'\n",
       "                                   '    if (line.startsWith(\"@@\")) {\\n'\n",
       "                                   '      // This is a chunk header. Parse the '\n",
       "                                   'line numbers.\\n'\n",
       "                                   '      const match = line.match(/@@ '\n",
       "                                   '-\\\\d+,\\\\d+ \\\\+(\\\\d+),\\\\d+ @@/);\\n'\n",
       "                                   '      newLine = parseInt(match[1]);\\n'\n",
       "                                   '      lineNumbers.push(line); // keep '\n",
       "                                   'chunk headers as is\\n'\n",
       "                                   '    } else if (!line.startsWith(\"-\")) {\\n'\n",
       "                                   '      // This is a line from the new '\n",
       "                                   'file.\\n'\n",
       "                                   '      lineNumbers.push(`${newLine++}: '\n",
       "                                   '${line}`);\\n'\n",
       "                                   '    }\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '\\n'\n",
       "                                   '  return lineNumbers.join(\"\\\\n\");\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const buildSuggestionPrompt = '\n",
       "                                   '(file: PRFile) => {\\n'\n",
       "                                   '  const rawPatch = '\n",
       "                                   'String.raw`${file.patch}`;\\n'\n",
       "                                   '  const patchWithLines = '\n",
       "                                   'assignLineNumbers(rawPatch);\\n'\n",
       "                                   '  return `## '\n",
       "                                   '${file.filename}\\\\n\\\\n${patchWithLines}`;\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const buildPatchPrompt = (file: '\n",
       "                                   'PRFile) => {\\n'\n",
       "                                   '  if (file.old_contents == null) {\\n'\n",
       "                                   '    return rawPatchStrategy(file);\\n'\n",
       "                                   '  } else {\\n'\n",
       "                                   '    return '\n",
       "                                   'smarterContextPatchStrategy(file);\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const getReviewPrompt = (diff: '\n",
       "                                   'string): ChatCompletionMessageParam[] => '\n",
       "                                   '{\\n'\n",
       "                                   '  return [\\n'\n",
       "                                   '    { role: \"system\", content: '\n",
       "                                   'REVIEW_DIFF_PROMPT },\\n'\n",
       "                                   '    { role: \"user\", content: diff },\\n'\n",
       "                                   '  ];\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const getXMLReviewPrompt = (\\n'\n",
       "                                   '  diff: string\\n'\n",
       "                                   '): ChatCompletionMessageParam[] => {\\n'\n",
       "                                   '  return [\\n'\n",
       "                                   '    { role: \"system\", content: '\n",
       "                                   'XML_PR_REVIEW_PROMPT },\\n'\n",
       "                                   '    { role: \"user\", content: diff },\\n'\n",
       "                                   '  ];\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const constructPrompt = (\\n'\n",
       "                                   '  files: PRFile[],\\n'\n",
       "                                   '  patchBuilder: (file: PRFile) => string,\\n'\n",
       "                                   '  convoBuilder: (diff: string) => '\n",
       "                                   'ChatCompletionMessageParam[]\\n'\n",
       "                                   ') => {\\n'\n",
       "                                   '  const patches = files.map((file) => '\n",
       "                                   'patchBuilder(file));\\n'\n",
       "                                   '  const diff = patches.join(\"\\\\n\");\\n'\n",
       "                                   '  const convo = convoBuilder(diff);\\n'\n",
       "                                   '  return convo;\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const getTokenLength = (blob: '\n",
       "                                   'string) => {\\n'\n",
       "                                   '  return encode(blob).length;\\n'\n",
       "                                   '};\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const isConversationWithinLimit = '\n",
       "                                   '(\\n'\n",
       "                                   '  convo: any[],\\n'\n",
       "                                   '  model: GroqChatModel = GROQ_MODEL\\n'\n",
       "                                   ') => {\\n'\n",
       "                                   \"  // We don't have the encoder for our \"\n",
       "                                   \"Groq model, so we're using\\n\"\n",
       "                                   '  // the one for gpt-3.5-turbo as a rough '\n",
       "                                   'equivalent.\\n'\n",
       "                                   '  const convoTokens = encodeChat(convo, '\n",
       "                                   '\"gpt-3.5-turbo\").length;\\n'\n",
       "                                   '  return convoTokens < '\n",
       "                                   'ModelsToTokenLimits[model];\\n'\n",
       "                                   '};\\n'},\n",
       "              'score': 0.1538167,\n",
       "              'values': []},\n",
       "             {'id': '8b05401c-8e61-4b91-907d-ad5ae5799208',\n",
       "              'metadata': {'source': 'src/data/PRSuggestionImpl.ts',\n",
       "                           'text': 'src/data/PRSuggestionImpl.ts\\n'\n",
       "                                   'import { PRSuggestion } from '\n",
       "                                   '\"../constants\";\\n'\n",
       "                                   '\\n'\n",
       "                                   'export class PRSuggestionImpl implements '\n",
       "                                   'PRSuggestion {\\n'\n",
       "                                   '  describe: string;\\n'\n",
       "                                   '  type: string;\\n'\n",
       "                                   '  comment: string;\\n'\n",
       "                                   '  code: string;\\n'\n",
       "                                   '  filename: string;\\n'\n",
       "                                   '\\n'\n",
       "                                   '  constructor(\\n'\n",
       "                                   '    describe: string,\\n'\n",
       "                                   '    type: string,\\n'\n",
       "                                   '    comment: string,\\n'\n",
       "                                   '    code: string,\\n'\n",
       "                                   '    filename: string\\n'\n",
       "                                   '  ) {\\n'\n",
       "                                   '    this.describe = describe;\\n'\n",
       "                                   '    this.type = type;\\n'\n",
       "                                   '    this.comment = comment;\\n'\n",
       "                                   '    this.code = code;\\n'\n",
       "                                   '    this.filename = filename;\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '\\n'\n",
       "                                   '  toString(): string {\\n'\n",
       "                                   '    const xmlElements = [\\n'\n",
       "                                   '      `<suggestion>`,\\n'\n",
       "                                   '      `  '\n",
       "                                   '<describe>${this.describe}</describe>`,\\n'\n",
       "                                   '      `  <type>${this.type}</type>`,\\n'\n",
       "                                   '      `  '\n",
       "                                   '<comment>${this.comment}</comment>`,\\n'\n",
       "                                   '      `  <code>${this.code}</code>`,\\n'\n",
       "                                   '      `  '\n",
       "                                   '<filename>${this.filename}</filename>`,\\n'\n",
       "                                   '      `</suggestion>`,\\n'\n",
       "                                   '    ];\\n'\n",
       "                                   '    return xmlElements.join(\"\\\\n\");\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '\\n'\n",
       "                                   '  identity(): string {\\n'\n",
       "                                   '    return '\n",
       "                                   '`${this.filename}:${this.comment}`;\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '}\\n'},\n",
       "              'score': 0.111635424,\n",
       "              'values': []},\n",
       "             {'id': '6cba83df-79b3-402c-b2be-9c84cafc7eea',\n",
       "              'metadata': {'source': 'src/env.ts',\n",
       "                           'text': 'src/env.ts\\n'\n",
       "                                   'import * as dotenv from \"dotenv\";\\n'\n",
       "                                   'import { createPrivateKey } from '\n",
       "                                   '\"crypto\";\\n'\n",
       "                                   'import chalk from \"chalk\";\\n'\n",
       "                                   '\\n'\n",
       "                                   'dotenv.config();\\n'\n",
       "                                   '\\n'\n",
       "                                   'export const env = {\\n'\n",
       "                                   '  GITHUB_APP_ID: '\n",
       "                                   'process.env.GITHUB_APP_ID,\\n'\n",
       "                                   '  GITHUB_PRIVATE_KEY: '\n",
       "                                   'process.env.GITHUB_PRIVATE_KEY,\\n'\n",
       "                                   '  GITHUB_WEBHOOK_SECRET: '\n",
       "                                   'process.env.GITHUB_WEBHOOK_SECRET,\\n'\n",
       "                                   '  GROQ_API_KEY: process.env.GROQ_API_KEY,\\n'\n",
       "                                   '} as const;\\n'\n",
       "                                   '\\n'\n",
       "                                   'let valid = true;\\n'\n",
       "                                   '\\n'\n",
       "                                   'for (const key in env) {\\n'\n",
       "                                   '  if (!env[key as keyof typeof env]) {\\n'\n",
       "                                   '    console.log(\\n'\n",
       "                                   '      chalk.red(\"✖\") +\\n'\n",
       "                                   '        chalk.gray(\" Missing required env '\n",
       "                                   'var: \") +\\n'\n",
       "                                   '        chalk.bold(`process.env.${key}`)\\n'\n",
       "                                   '    );\\n'\n",
       "                                   '    valid = false;\\n'\n",
       "                                   '  }\\n'\n",
       "                                   '}\\n'\n",
       "                                   '\\n'\n",
       "                                   'try {\\n'\n",
       "                                   '  '\n",
       "                                   'createPrivateKey(env.GITHUB_PRIVATE_KEY);\\n'\n",
       "                                   '} catch (error) {\\n'\n",
       "                                   '  console.log(\\n'\n",
       "                                   '    chalk.red(\\n'\n",
       "                                   '      \"\\\\n✖ Invalid GitHub private key '\n",
       "                                   'format for \" +\\n'\n",
       "                                   '        '\n",
       "                                   'chalk.bold(`process.env.GITHUB_PRIVATE_KEY`) '\n",
       "                                   '+\\n'\n",
       "                                   '        \"\\\\n\"\\n'\n",
       "                                   '    ) +\\n'\n",
       "                                   '      chalk.gray(\"  • Must start with: \") '\n",
       "                                   '+\\n'\n",
       "                                   '      chalk.bold(\"-----BEGIN RSA PRIVATE '\n",
       "                                   'KEY-----\\\\n\") +\\n'\n",
       "                                   '      chalk.gray(\"  • Must end with:   \") '\n",
       "                                   '+\\n'\n",
       "                                   '      chalk.bold(\"-----END RSA PRIVATE '\n",
       "                                   'KEY-----\\\\n\")\\n'\n",
       "                                   '  );\\n'\n",
       "                                   '  valid = false;\\n'\n",
       "                                   '}\\n'\n",
       "                                   '\\n'\n",
       "                                   'if (!valid) {\\n'\n",
       "                                   '  console.log(\\n'\n",
       "                                   '    chalk.yellow(\"\\\\n⚠ \") +\\n'\n",
       "                                   '      chalk.bold(\"Please check your .env '\n",
       "                                   'file and try again.\\\\n\")\\n'\n",
       "                                   '  );\\n'\n",
       "                                   '  process.exit(1);\\n'\n",
       "                                   '}\\n'},\n",
       "              'score': 0.0930456,\n",
       "              'values': []}],\n",
       " 'namespace': 'https://github.com/CoderAgent/SecureAgent',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [item['metadata']['text'] for item in top_matches['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n',\n",
       " 'src/context/language/javascript-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nimport * as parser from \"@babel/parser\";\\nimport traverse, { NodePath, Node } from \"@babel/traverse\";\\n\\nconst processNode = (\\n  path: NodePath<Node>,\\n  lineStart: number,\\n  lineEnd: number,\\n  largestSize: number,\\n  largestEnclosingContext: Node | null\\n) => {\\n  const { start, end } = path.node.loc;\\n  if (start.line <= lineStart && lineEnd <= end.line) {\\n    const size = end.line - start.line;\\n    if (size > largestSize) {\\n      largestSize = size;\\n      largestEnclosingContext = path.node;\\n    }\\n  }\\n  return { largestSize, largestEnclosingContext };\\n};\\n\\nexport class JavascriptParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    const ast = parser.parse(file, {\\n      sourceType: \"module\",\\n      plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n    });\\n    let largestEnclosingContext: Node = null;\\n    let largestSize = 0;\\n    traverse(ast, {\\n      Function(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n      TSInterfaceDeclaration(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n    });\\n    return {\\n      enclosingContext: largestEnclosingContext,\\n    } as EnclosingContext;\\n  }\\n\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    try {\\n      const ast = parser.parse(file, {\\n        sourceType: \"module\",\\n        plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n      });\\n      return {\\n        valid: true,\\n        error: \"\",\\n      };\\n    } catch (exc) {\\n      return {\\n        valid: false,\\n        error: exc,\\n      };\\n    }\\n  }\\n}\\n',\n",
       " 'src/prompts.ts\\nimport { encode, encodeChat } from \"gpt-tokenizer\";\\nimport type { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport type { PRFile } from \"./constants\";\\nimport {\\n  rawPatchStrategy,\\n  smarterContextPatchStrategy,\\n} from \"./context/review\";\\nimport { GROQ_MODEL, type GroqChatModel } from \"./llms/groq\";\\n\\nconst ModelsToTokenLimits: Record<GroqChatModel, number> = {\\n  \"mixtral-8x7b-32768\": 32768,\\n  \"gemma-7b-it\": 32768,\\n  \"llama3-70b-8192\": 8192,\\n  \"llama3-8b-8192\": 8192,\\n};\\n\\nexport const REVIEW_DIFF_PROMPT = `You are PR-Reviewer, a language model designed to review git pull requests.\\nYour task is to provide constructive and concise feedback for the PR, and also provide meaningful code suggestions.\\n\\nExample PR Diff input:\\n\\'\\n## src/file1.py\\n\\n@@ -12,5 +12,5 @@ def func1():\\ncode line that already existed in the file...\\ncode line that already existed in the file....\\n-code line that was removed in the PR\\n+new code line added in the PR\\n code line that already existed in the file...\\n code line that already existed in the file...\\n\\n@@ ... @@ def func2():\\n...\\n\\n\\n## src/file2.py\\n...\\n\\'\\n\\nThe review should focus on new code added in the PR (lines starting with \\'+\\'), and not on code that already existed in the file (lines starting with \\'-\\', or without prefix).\\n\\n- ONLY PROVIDE CODE SUGGESTIONS\\n- Focus on important suggestions like fixing code problems, improving performance, improving security, improving readability\\n- Avoid making suggestions that have already been implemented in the PR code. For example, if you want to add logs, or change a variable to const, or anything else, make sure it isn\\'t already in the PR code.\\n- Don\\'t suggest adding docstring, type hints, or comments.\\n- Suggestions should focus on improving the new code added in the PR (lines starting with \\'+\\')\\n- Do not say things like without seeing the full repo, or full code, or rest of the codebase. Comment only on the code you have!\\n\\nMake sure the provided code suggestions are in the same programming language.\\n\\nDon\\'t repeat the prompt in the answer, and avoid outputting the \\'type\\' and \\'description\\' fields.\\n\\nThink through your suggestions and make exceptional improvements.`;\\n\\nexport const XML_PR_REVIEW_PROMPT = `As the PR-Reviewer AI model, you are tasked to analyze git pull requests across any programming language and provide comprehensive and precise code enhancements. Keep your focus on the new code modifications indicated by \\'+\\' lines in the PR. Your feedback should hunt for code issues, opportunities for performance enhancement, security improvements, and ways to increase readability. \\n\\nEnsure your suggestions are novel and haven\\'t been previously incorporated in the \\'+\\' lines of the PR code. Refrain from proposing enhancements that add docstrings, type hints, or comments. Your recommendations should strictly target the \\'+\\' lines without suggesting the need for complete context such as the whole repo or codebase.\\n\\nYour code suggestions should match the programming language in the PR, steer clear of needless repetition or inclusion of \\'type\\' and \\'description\\' fields.\\n\\nFormulate thoughtful suggestions aimed at strengthening performance, security, and readability, and represent them in an XML format utilizing the tags: <review>, <code>, <suggestion>, <comment>, <type>, <describe>, <filename>. While multiple recommendations can be given, they should all reside within one <review> tag.\\n\\nAlso note, all your code suggestions should follow the valid Markdown syntax for GitHub, identifying the language they\\'re written in, and should be enclosed within backticks (\\\\`\\\\`\\\\`). \\n\\nDon\\'t hesitate to add as many constructive suggestions as are relevant to really improve the effectivity of the code.\\n\\nExample output:\\n\\\\`\\\\`\\\\`\\n<review>\\n  <suggestion>\\n    <describe>[Objective of the newly incorporated code]</describe>\\n    <type>[Category of the given suggestion such as performance, security, etc.]</type>\\n    <comment>[Guidance on enhancing the new code]</comment>\\n    <code>\\n    \\\\`\\\\`\\\\`[Programming Language]\\n    [Equivalent code amendment in the same language]\\n    \\\\`\\\\`\\\\`\\n    </code>\\n    <filename>[name of relevant file]</filename>\\n  </suggestion>\\n  <suggestion>\\n  ...\\n  </suggestion>\\n  ...\\n</review>\\n\\\\`\\\\`\\\\`\\n\\nNote: The \\'comment\\' and \\'describe\\' tags should elucidate the advice and why it’s given, while the \\'code\\' tag hosts the recommended code snippet within proper GitHub Markdown syntax. The \\'type\\' defines the suggestion\\'s category such as performance, security, readability, etc.`;\\n\\nexport const PR_SUGGESTION_TEMPLATE = `{COMMENT}\\n{ISSUE_LINK}\\n\\n{CODE}\\n`;\\n\\nconst assignLineNumbers = (diff: string) => {\\n  const lines = diff.split(\"\\\\n\");\\n  let newLine = 0;\\n  const lineNumbers = [];\\n\\n  for (const line of lines) {\\n    if (line.startsWith(\"@@\")) {\\n      // This is a chunk header. Parse the line numbers.\\n      const match = line.match(/@@ -\\\\d+,\\\\d+ \\\\+(\\\\d+),\\\\d+ @@/);\\n      newLine = parseInt(match[1]);\\n      lineNumbers.push(line); // keep chunk headers as is\\n    } else if (!line.startsWith(\"-\")) {\\n      // This is a line from the new file.\\n      lineNumbers.push(`${newLine++}: ${line}`);\\n    }\\n  }\\n\\n  return lineNumbers.join(\"\\\\n\");\\n};\\n\\nexport const buildSuggestionPrompt = (file: PRFile) => {\\n  const rawPatch = String.raw`${file.patch}`;\\n  const patchWithLines = assignLineNumbers(rawPatch);\\n  return `## ${file.filename}\\\\n\\\\n${patchWithLines}`;\\n};\\n\\nexport const buildPatchPrompt = (file: PRFile) => {\\n  if (file.old_contents == null) {\\n    return rawPatchStrategy(file);\\n  } else {\\n    return smarterContextPatchStrategy(file);\\n  }\\n};\\n\\nexport const getReviewPrompt = (diff: string): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: REVIEW_DIFF_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const getXMLReviewPrompt = (\\n  diff: string\\n): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: XML_PR_REVIEW_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const constructPrompt = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const patches = files.map((file) => patchBuilder(file));\\n  const diff = patches.join(\"\\\\n\");\\n  const convo = convoBuilder(diff);\\n  return convo;\\n};\\n\\nexport const getTokenLength = (blob: string) => {\\n  return encode(blob).length;\\n};\\n\\nexport const isConversationWithinLimit = (\\n  convo: any[],\\n  model: GroqChatModel = GROQ_MODEL\\n) => {\\n  // We don\\'t have the encoder for our Groq model, so we\\'re using\\n  // the one for gpt-3.5-turbo as a rough equivalent.\\n  const convoTokens = encodeChat(convo, \"gpt-3.5-turbo\").length;\\n  return convoTokens < ModelsToTokenLimits[model];\\n};\\n',\n",
       " 'src/data/PRSuggestionImpl.ts\\nimport { PRSuggestion } from \"../constants\";\\n\\nexport class PRSuggestionImpl implements PRSuggestion {\\n  describe: string;\\n  type: string;\\n  comment: string;\\n  code: string;\\n  filename: string;\\n\\n  constructor(\\n    describe: string,\\n    type: string,\\n    comment: string,\\n    code: string,\\n    filename: string\\n  ) {\\n    this.describe = describe;\\n    this.type = type;\\n    this.comment = comment;\\n    this.code = code;\\n    this.filename = filename;\\n  }\\n\\n  toString(): string {\\n    const xmlElements = [\\n      `<suggestion>`,\\n      `  <describe>${this.describe}</describe>`,\\n      `  <type>${this.type}</type>`,\\n      `  <comment>${this.comment}</comment>`,\\n      `  <code>${this.code}</code>`,\\n      `  <filename>${this.filename}</filename>`,\\n      `</suggestion>`,\\n    ];\\n    return xmlElements.join(\"\\\\n\");\\n  }\\n\\n  identity(): string {\\n    return `${this.filename}:${this.comment}`;\\n  }\\n}\\n',\n",
       " 'src/env.ts\\nimport * as dotenv from \"dotenv\";\\nimport { createPrivateKey } from \"crypto\";\\nimport chalk from \"chalk\";\\n\\ndotenv.config();\\n\\nexport const env = {\\n  GITHUB_APP_ID: process.env.GITHUB_APP_ID,\\n  GITHUB_PRIVATE_KEY: process.env.GITHUB_PRIVATE_KEY,\\n  GITHUB_WEBHOOK_SECRET: process.env.GITHUB_WEBHOOK_SECRET,\\n  GROQ_API_KEY: process.env.GROQ_API_KEY,\\n} as const;\\n\\nlet valid = true;\\n\\nfor (const key in env) {\\n  if (!env[key as keyof typeof env]) {\\n    console.log(\\n      chalk.red(\"✖\") +\\n        chalk.gray(\" Missing required env var: \") +\\n        chalk.bold(`process.env.${key}`)\\n    );\\n    valid = false;\\n  }\\n}\\n\\ntry {\\n  createPrivateKey(env.GITHUB_PRIVATE_KEY);\\n} catch (error) {\\n  console.log(\\n    chalk.red(\\n      \"\\\\n✖ Invalid GitHub private key format for \" +\\n        chalk.bold(`process.env.GITHUB_PRIVATE_KEY`) +\\n        \"\\\\n\"\\n    ) +\\n      chalk.gray(\"  • Must start with: \") +\\n      chalk.bold(\"-----BEGIN RSA PRIVATE KEY-----\\\\n\") +\\n      chalk.gray(\"  • Must end with:   \") +\\n      chalk.bold(\"-----END RSA PRIVATE KEY-----\\\\n\")\\n  );\\n  valid = false;\\n}\\n\\nif (!valid) {\\n  console.log(\\n    chalk.yellow(\"\\\\n⚠ \") +\\n      chalk.bold(\"Please check your .env file and try again.\\\\n\")\\n  );\\n  process.exit(1);\\n}\\n']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CONTEXT>\n",
      "src/context/language/python-parser.ts\n",
      "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
      "export class PythonParser implements AbstractParser {\n",
      "  findEnclosingContext(\n",
      "    file: string,\n",
      "    lineStart: number,\n",
      "    lineEnd: number\n",
      "  ): EnclosingContext {\n",
      "    // TODO: Implement this method for Python\n",
      "    return null;\n",
      "  }\n",
      "  dryRun(file: string): { valid: boolean; error: string } {\n",
      "    // TODO: Implement this method for Python\n",
      "    return { valid: false, error: \"Not implemented yet\" };\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "src/context/language/javascript-parser.ts\n",
      "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
      "import * as parser from \"@babel/parser\";\n",
      "import traverse, { NodePath, Node } from \"@babel/traverse\";\n",
      "\n",
      "const processNode = (\n",
      "  path: NodePath<Node>,\n",
      "  lineStart: number,\n",
      "  lineEnd: number,\n",
      "  largestSize: number,\n",
      "  largestEnclosingContext: Node | null\n",
      ") => {\n",
      "  const { start, end } = path.node.loc;\n",
      "  if (start.line <= lineStart && lineEnd <= end.line) {\n",
      "    const size = end.line - start.line;\n",
      "    if (size > largestSize) {\n",
      "      largestSize = size;\n",
      "      largestEnclosingContext = path.node;\n",
      "    }\n",
      "  }\n",
      "  return { largestSize, largestEnclosingContext };\n",
      "};\n",
      "\n",
      "export class JavascriptParser implements AbstractParser {\n",
      "  findEnclosingContext(\n",
      "    file: string,\n",
      "    lineStart: number,\n",
      "    lineEnd: number\n",
      "  ): EnclosingContext {\n",
      "    const ast = parser.parse(file, {\n",
      "      sourceType: \"module\",\n",
      "      plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\n",
      "    });\n",
      "    let largestEnclosingContext: Node = null;\n",
      "    let largestSize = 0;\n",
      "    traverse(ast, {\n",
      "      Function(path) {\n",
      "        ({ largestSize, largestEnclosingContext } = processNode(\n",
      "          path,\n",
      "          lineStart,\n",
      "          lineEnd,\n",
      "          largestSize,\n",
      "          largestEnclosingContext\n",
      "        ));\n",
      "      },\n",
      "      TSInterfaceDeclaration(path) {\n",
      "        ({ largestSize, largestEnclosingContext } = processNode(\n",
      "          path,\n",
      "          lineStart,\n",
      "          lineEnd,\n",
      "          largestSize,\n",
      "          largestEnclosingContext\n",
      "        ));\n",
      "      },\n",
      "    });\n",
      "    return {\n",
      "      enclosingContext: largestEnclosingContext,\n",
      "    } as EnclosingContext;\n",
      "  }\n",
      "\n",
      "  dryRun(file: string): { valid: boolean; error: string } {\n",
      "    try {\n",
      "      const ast = parser.parse(file, {\n",
      "        sourceType: \"module\",\n",
      "        plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\n",
      "      });\n",
      "      return {\n",
      "        valid: true,\n",
      "        error: \"\",\n",
      "      };\n",
      "    } catch (exc) {\n",
      "      return {\n",
      "        valid: false,\n",
      "        error: exc,\n",
      "      };\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "src/prompts.ts\n",
      "import { encode, encodeChat } from \"gpt-tokenizer\";\n",
      "import type { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\n",
      "import type { PRFile } from \"./constants\";\n",
      "import {\n",
      "  rawPatchStrategy,\n",
      "  smarterContextPatchStrategy,\n",
      "} from \"./context/review\";\n",
      "import { GROQ_MODEL, type GroqChatModel } from \"./llms/groq\";\n",
      "\n",
      "const ModelsToTokenLimits: Record<GroqChatModel, number> = {\n",
      "  \"mixtral-8x7b-32768\": 32768,\n",
      "  \"gemma-7b-it\": 32768,\n",
      "  \"llama3-70b-8192\": 8192,\n",
      "  \"llama3-8b-8192\": 8192,\n",
      "};\n",
      "\n",
      "export const REVIEW_DIFF_PROMPT = `You are PR-Reviewer, a language model designed to review git pull requests.\n",
      "Your task is to provide constructive and concise feedback for the PR, and also provide meaningful code suggestions.\n",
      "\n",
      "Example PR Diff input:\n",
      "'\n",
      "## src/file1.py\n",
      "\n",
      "@@ -12,5 +12,5 @@ def func1():\n",
      "code line that already existed in the file...\n",
      "code line that already existed in the file....\n",
      "-code line that was removed in the PR\n",
      "+new code line added in the PR\n",
      " code line that already existed in the file...\n",
      " code line that already existed in the file...\n",
      "\n",
      "@@ ... @@ def func2():\n",
      "...\n",
      "\n",
      "\n",
      "## src/file2.py\n",
      "...\n",
      "'\n",
      "\n",
      "The review should focus on new code added in the PR (lines starting with '+'), and not on code that already existed in the file (lines starting with '-', or without prefix).\n",
      "\n",
      "- ONLY PROVIDE CODE SUGGESTIONS\n",
      "- Focus on important suggestions like fixing code problems, improving performance, improving security, improving readability\n",
      "- Avoid making suggestions that have already been implemented in the PR code. For example, if you want to add logs, or change a variable to const, or anything else, make sure it isn't already in the PR code.\n",
      "- Don't suggest adding docstring, type hints, or comments.\n",
      "- Suggestions should focus on improving the new code added in the PR (lines starting with '+')\n",
      "- Do not say things like without seeing the full repo, or full code, or rest of the codebase. Comment only on the code you have!\n",
      "\n",
      "Make sure the provided code suggestions are in the same programming language.\n",
      "\n",
      "Don't repeat the prompt in the answer, and avoid outputting the 'type' and 'description' fields.\n",
      "\n",
      "Think through your suggestions and make exceptional improvements.`;\n",
      "\n",
      "export const XML_PR_REVIEW_PROMPT = `As the PR-Reviewer AI model, you are tasked to analyze git pull requests across any programming language and provide comprehensive and precise code enhancements. Keep your focus on the new code modifications indicated by '+' lines in the PR. Your feedback should hunt for code issues, opportunities for performance enhancement, security improvements, and ways to increase readability. \n",
      "\n",
      "Ensure your suggestions are novel and haven't been previously incorporated in the '+' lines of the PR code. Refrain from proposing enhancements that add docstrings, type hints, or comments. Your recommendations should strictly target the '+' lines without suggesting the need for complete context such as the whole repo or codebase.\n",
      "\n",
      "Your code suggestions should match the programming language in the PR, steer clear of needless repetition or inclusion of 'type' and 'description' fields.\n",
      "\n",
      "Formulate thoughtful suggestions aimed at strengthening performance, security, and readability, and represent them in an XML format utilizing the tags: <review>, <code>, <suggestion>, <comment>, <type>, <describe>, <filename>. While multiple recommendations can be given, they should all reside within one <review> tag.\n",
      "\n",
      "Also note, all your code suggestions should follow the valid Markdown syntax for GitHub, identifying the language they're written in, and should be enclosed within backticks (\\`\\`\\`). \n",
      "\n",
      "Don't hesitate to add as many constructive suggestions as are relevant to really improve the effectivity of the code.\n",
      "\n",
      "Example output:\n",
      "\\`\\`\\`\n",
      "<review>\n",
      "  <suggestion>\n",
      "    <describe>[Objective of the newly incorporated code]</describe>\n",
      "    <type>[Category of the given suggestion such as performance, security, etc.]</type>\n",
      "    <comment>[Guidance on enhancing the new code]</comment>\n",
      "    <code>\n",
      "    \\`\\`\\`[Programming Language]\n",
      "    [Equivalent code amendment in the same language]\n",
      "    \\`\\`\\`\n",
      "    </code>\n",
      "    <filename>[name of relevant file]</filename>\n",
      "  </suggestion>\n",
      "  <suggestion>\n",
      "  ...\n",
      "  </suggestion>\n",
      "  ...\n",
      "</review>\n",
      "\\`\\`\\`\n",
      "\n",
      "Note: The 'comment' and 'describe' tags should elucidate the advice and why it’s given, while the 'code' tag hosts the recommended code snippet within proper GitHub Markdown syntax. The 'type' defines the suggestion's category such as performance, security, readability, etc.`;\n",
      "\n",
      "export const PR_SUGGESTION_TEMPLATE = `{COMMENT}\n",
      "{ISSUE_LINK}\n",
      "\n",
      "{CODE}\n",
      "`;\n",
      "\n",
      "const assignLineNumbers = (diff: string) => {\n",
      "  const lines = diff.split(\"\\n\");\n",
      "  let newLine = 0;\n",
      "  const lineNumbers = [];\n",
      "\n",
      "  for (const line of lines) {\n",
      "    if (line.startsWith(\"@@\")) {\n",
      "      // This is a chunk header. Parse the line numbers.\n",
      "      const match = line.match(/@@ -\\d+,\\d+ \\+(\\d+),\\d+ @@/);\n",
      "      newLine = parseInt(match[1]);\n",
      "      lineNumbers.push(line); // keep chunk headers as is\n",
      "    } else if (!line.startsWith(\"-\")) {\n",
      "      // This is a line from the new file.\n",
      "      lineNumbers.push(`${newLine++}: ${line}`);\n",
      "    }\n",
      "  }\n",
      "\n",
      "  return lineNumbers.join(\"\\n\");\n",
      "};\n",
      "\n",
      "export const buildSuggestionPrompt = (file: PRFile) => {\n",
      "  const rawPatch = String.raw`${file.patch}`;\n",
      "  const patchWithLines = assignLineNumbers(rawPatch);\n",
      "  return `## ${file.filename}\\n\\n${patchWithLines}`;\n",
      "};\n",
      "\n",
      "export const buildPatchPrompt = (file: PRFile) => {\n",
      "  if (file.old_contents == null) {\n",
      "    return rawPatchStrategy(file);\n",
      "  } else {\n",
      "    return smarterContextPatchStrategy(file);\n",
      "  }\n",
      "};\n",
      "\n",
      "export const getReviewPrompt = (diff: string): ChatCompletionMessageParam[] => {\n",
      "  return [\n",
      "    { role: \"system\", content: REVIEW_DIFF_PROMPT },\n",
      "    { role: \"user\", content: diff },\n",
      "  ];\n",
      "};\n",
      "\n",
      "export const getXMLReviewPrompt = (\n",
      "  diff: string\n",
      "): ChatCompletionMessageParam[] => {\n",
      "  return [\n",
      "    { role: \"system\", content: XML_PR_REVIEW_PROMPT },\n",
      "    { role: \"user\", content: diff },\n",
      "  ];\n",
      "};\n",
      "\n",
      "export const constructPrompt = (\n",
      "  files: PRFile[],\n",
      "  patchBuilder: (file: PRFile) => string,\n",
      "  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\n",
      ") => {\n",
      "  const patches = files.map((file) => patchBuilder(file));\n",
      "  const diff = patches.join(\"\\n\");\n",
      "  const convo = convoBuilder(diff);\n",
      "  return convo;\n",
      "};\n",
      "\n",
      "export const getTokenLength = (blob: string) => {\n",
      "  return encode(blob).length;\n",
      "};\n",
      "\n",
      "export const isConversationWithinLimit = (\n",
      "  convo: any[],\n",
      "  model: GroqChatModel = GROQ_MODEL\n",
      ") => {\n",
      "  // We don't have the encoder for our Groq model, so we're using\n",
      "  // the one for gpt-3.5-turbo as a rough equivalent.\n",
      "  const convoTokens = encodeChat(convo, \"gpt-3.5-turbo\").length;\n",
      "  return convoTokens < ModelsToTokenLimits[model];\n",
      "};\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "src/data/PRSuggestionImpl.ts\n",
      "import { PRSuggestion } from \"../constants\";\n",
      "\n",
      "export class PRSuggestionImpl implements PRSuggestion {\n",
      "  describe: string;\n",
      "  type: string;\n",
      "  comment: string;\n",
      "  code: string;\n",
      "  filename: string;\n",
      "\n",
      "  constructor(\n",
      "    describe: string,\n",
      "    type: string,\n",
      "    comment: string,\n",
      "    code: string,\n",
      "    filename: string\n",
      "  ) {\n",
      "    this.describe = describe;\n",
      "    this.type = type;\n",
      "    this.comment = comment;\n",
      "    this.code = code;\n",
      "    this.filename = filename;\n",
      "  }\n",
      "\n",
      "  toString(): string {\n",
      "    const xmlElements = [\n",
      "      `<suggestion>`,\n",
      "      `  <describe>${this.describe}</describe>`,\n",
      "      `  <type>${this.type}</type>`,\n",
      "      `  <comment>${this.comment}</comment>`,\n",
      "      `  <code>${this.code}</code>`,\n",
      "      `  <filename>${this.filename}</filename>`,\n",
      "      `</suggestion>`,\n",
      "    ];\n",
      "    return xmlElements.join(\"\\n\");\n",
      "  }\n",
      "\n",
      "  identity(): string {\n",
      "    return `${this.filename}:${this.comment}`;\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "src/env.ts\n",
      "import * as dotenv from \"dotenv\";\n",
      "import { createPrivateKey } from \"crypto\";\n",
      "import chalk from \"chalk\";\n",
      "\n",
      "dotenv.config();\n",
      "\n",
      "export const env = {\n",
      "  GITHUB_APP_ID: process.env.GITHUB_APP_ID,\n",
      "  GITHUB_PRIVATE_KEY: process.env.GITHUB_PRIVATE_KEY,\n",
      "  GITHUB_WEBHOOK_SECRET: process.env.GITHUB_WEBHOOK_SECRET,\n",
      "  GROQ_API_KEY: process.env.GROQ_API_KEY,\n",
      "} as const;\n",
      "\n",
      "let valid = true;\n",
      "\n",
      "for (const key in env) {\n",
      "  if (!env[key as keyof typeof env]) {\n",
      "    console.log(\n",
      "      chalk.red(\"✖\") +\n",
      "        chalk.gray(\" Missing required env var: \") +\n",
      "        chalk.bold(`process.env.${key}`)\n",
      "    );\n",
      "    valid = false;\n",
      "  }\n",
      "}\n",
      "\n",
      "try {\n",
      "  createPrivateKey(env.GITHUB_PRIVATE_KEY);\n",
      "} catch (error) {\n",
      "  console.log(\n",
      "    chalk.red(\n",
      "      \"\\n✖ Invalid GitHub private key format for \" +\n",
      "        chalk.bold(`process.env.GITHUB_PRIVATE_KEY`) +\n",
      "        \"\\n\"\n",
      "    ) +\n",
      "      chalk.gray(\"  • Must start with: \") +\n",
      "      chalk.bold(\"-----BEGIN RSA PRIVATE KEY-----\\n\") +\n",
      "      chalk.gray(\"  • Must end with:   \") +\n",
      "      chalk.bold(\"-----END RSA PRIVATE KEY-----\\n\")\n",
      "  );\n",
      "  valid = false;\n",
      "}\n",
      "\n",
      "if (!valid) {\n",
      "  console.log(\n",
      "    chalk.yellow(\"\\n⚠ \") +\n",
      "      chalk.bold(\"Please check your .env file and try again.\\n\")\n",
      "  );\n",
      "  process.exit(1);\n",
      "}\n",
      "\n",
      "-------\n",
      "</CONTEXT>\n",
      "\n",
      "\n",
      "\n",
      "MY QUESTION:\n",
      "How are python files parsed?\n"
     ]
    }
   ],
   "source": [
    "# print(augmented_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript.\n",
    "\n",
    "# Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
    "# \"\"\"\n",
    "\n",
    "# llm_response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": system_prompt},\n",
    "#         {\"role\": \"user\", \"content\": augmented_query}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# response = llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Currently, Python files are not yet parsed. The `PythonParser` class in `src/context/language/python-parser.ts` implements the `AbstractParser` interface, but both of its methods, `findEnclosingContext` and `dryRun`, are not implemented. The `findEnclosingContext` method is meant to find and return the enclosing context within the Python code, but it currently returns `null`. Similarly, the `dryRun` method, which should validate Python files, returns an object indicating it is not implemented yet (with `valid: false` and `error: \"Not implemented yet\"`).\\n\\nThus, as of the provided context, Python files do not have a parsing implementation in the codebase.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_rag(query):\n",
    "#     raw_query_embedding = get_huggingface_embeddings(query)\n",
    "\n",
    "#     top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=\"https://github.com/CoderAgent/SecureAgent\")\n",
    "\n",
    "#     # Get the list of retrieved texts\n",
    "#     contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
    "\n",
    "#     augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
    "\n",
    "#     # Modify the prompt below as need to improve the response quality\n",
    "#     system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript.\n",
    "\n",
    "#     Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
    "#     \"\"\"\n",
    "\n",
    "#     llm_response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": augmented_query}\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     return llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JavaScript parser in the codebase is implemented by the `JavascriptParser` class in `src/context/language/javascript-parser.ts`. Here's a brief overview of how it is used across the codebase based on the provided context:\n",
      "\n",
      "1. **Parser Initialization:**\n",
      "   - The `JavascriptParser` is constructed and associated with specific file extensions through the `EXTENSIONS_TO_PARSERS` map in `src/constants.ts`. This map associates file extensions like `ts`, `tsx`, `js`, and `jsx` with the `JavascriptParser`.\n",
      "\n",
      "2. **Parser Selection:**\n",
      "   - The function `getParserForExtension` in `src/constants.ts` retrieves the appropriate parser for a file based on its extension by consulting the `EXTENSIONS_TO_PARSERS` map.\n",
      "\n",
      "3. **Usage in `smarterContextPatchStrategy`:**\n",
      "   - In `src/context/review.ts`, the `smarterContextPatchStrategy` function makes use of the parser by first obtaining it with `getParserForExtension(file.filename)`. If a parser is available for the file's extension (e.g., JavaScript or TypeScript files), it uses the `functionContextPatchStrategy`.\n",
      "\n",
      "4. **Function Context Strategy:**\n",
      "   - The `functionContextPatchStrategy` calls `diffContextPerHunk`, which, in turn, utilizes the `JavascriptParser` to find the largest enclosing context for changes in a patch. This involves analyzing AST nodes to determine the most relevant function or interface pertaining to the changes and potentially reorganizing diffs based on this context.\n",
      "\n",
      "5. **AST Parsing & Traversal:**\n",
      "   - Inside the `JavascriptParser`, the `findEnclosingContext` method parses the file into an AST using Babel’s parser, and then traverses the AST to find the largest context (such as a function or TypeScript interface) that entirely encompasses the specified line range.\n",
      "\n",
      "6. **Dry Run Validation:**\n",
      "   - The `JavascriptParser` also provides a `dryRun` method to check if the file is valid JavaScript/TypeScript code by attempting to parse it and catching any parsing errors.\n",
      "\n",
      "Overall, the JavaScript parser is primarily utilized for analyzing JavaScript/TypeScript files to provide contextual information that enhances how diffs are represented and reviewed.\n"
     ]
    }
   ],
   "source": [
    "# response = perform_rag(\"How is the javascript parser used?\")\n",
    "\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codebase-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
